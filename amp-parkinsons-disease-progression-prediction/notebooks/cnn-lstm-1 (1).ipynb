{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606664ce",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-06T22:20:42.427831Z",
     "iopub.status.busy": "2023-05-06T22:20:42.427321Z",
     "iopub.status.idle": "2023-05-06T22:20:42.449439Z",
     "shell.execute_reply": "2023-05-06T22:20:42.448728Z"
    },
    "papermill": {
     "duration": 0.030889,
     "end_time": "2023-05-06T22:20:42.451992",
     "exception": false,
     "start_time": "2023-05-06T22:20:42.421103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/public_timeseries_testing_util.py\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/__init__.py\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide_310/competition.cpython-310-x86_64-linux-gnu.so\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide_310/__init__.py\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/sample_submission.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadbf32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:20:42.460996Z",
     "iopub.status.busy": "2023-05-06T22:20:42.460301Z",
     "iopub.status.idle": "2023-05-06T22:20:51.503852Z",
     "shell.execute_reply": "2023-05-06T22:20:51.502662Z"
    },
    "papermill": {
     "duration": 9.051049,
     "end_time": "2023-05-06T22:20:51.506876",
     "exception": false,
     "start_time": "2023-05-06T22:20:42.455827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential, Model\n",
    "from tensorflow.keras import backend as kb\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be6c9de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:20:51.516792Z",
     "iopub.status.busy": "2023-05-06T22:20:51.516068Z",
     "iopub.status.idle": "2023-05-06T22:20:53.182479Z",
     "shell.execute_reply": "2023-05-06T22:20:53.181552Z"
    },
    "papermill": {
     "duration": 1.674113,
     "end_time": "2023-05-06T22:20:53.185011",
     "exception": false,
     "start_time": "2023-05-06T22:20:51.510898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\n",
    "df_train_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\n",
    "df_train_clinical = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83c815d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:20:53.195513Z",
     "iopub.status.busy": "2023-05-06T22:20:53.194843Z",
     "iopub.status.idle": "2023-05-06T22:20:53.238962Z",
     "shell.execute_reply": "2023-05-06T22:20:53.237762Z"
    },
    "papermill": {
     "duration": 0.052325,
     "end_time": "2023-05-06T22:20:53.241483",
     "exception": false,
     "start_time": "2023-05-06T22:20:53.189158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lin_reg(mat):\n",
    "    if mat.shape[0] == 1:\n",
    "        return 0, mat[0,1]\n",
    "    \n",
    "    X = mat[:,0]\n",
    "    X = np.vstack([X, np.ones(len(X))]).T\n",
    "    Y = mat[:,1]\n",
    "    \n",
    "    # res = np.dot(np.linalg.inv(X.T@X)@X.T, Y)            # This might be faster? (Uses pseudoinverse to calculate weights)\n",
    "    res = np.around(np.linalg.lstsq(X,Y, rcond=None)[0])\n",
    "    return res\n",
    "\n",
    "\n",
    "def lin_reg_imputation(df, complete=False, style='mean'):\n",
    "    global t0\n",
    "    # res = [0]*len(df.patient_id.unique())       # To preallocate a list, might be faster?\n",
    "    # i = 0                                       # If using preallocation\n",
    "    res= []\n",
    "    for patient, group in df.groupby('patient_id'):\n",
    "        months = group['visit_month']\n",
    "        for col in group:\n",
    "            data = group[col]\n",
    "            if data.isna().sum() not in (0, len(data)):\n",
    "                m,b = get_lin_reg(pd.concat([months,data], axis=1).dropna().values)\n",
    "                group[col].fillna(m*months + b, inplace=True)\n",
    "        res.append(group)\n",
    "        # res[i] = group                          # If using preallocation\n",
    "        # i += 1                                  # If using preallocation\n",
    "    df_linreg = pd.concat(res)\n",
    "    if complete:\n",
    "        if style=='mean':\n",
    "            df_linreg.fillna(df_linreg.mean(), inplace=True)\n",
    "        elif style=='zero':\n",
    "            df_linreg.fillna(0, inplace=True)\n",
    "        else:\n",
    "            raise Exception(f'\"{style}\" is not a valid imputation method. Available options are \"mean\" or \"zero\"')\n",
    "    return df_linreg\n",
    "\n",
    "\n",
    "def test_data_prep(proteins, uniprot_ids, scaler, shown, concat=True):\n",
    "    \n",
    "    # Remove extra proteins\n",
    "    new_uniprots = set(proteins.UniProt.unique())\n",
    "    extra_prots = new_uniprots.difference(uniprot_ids)\n",
    "    proteins = proteins.drop(extra_prots)\n",
    "    print('removed extras')\n",
    "    print(f'removed {extra_prots}')\n",
    "    \n",
    "    # Reshape\n",
    "    protein_pivot = df_train_proteins.pivot(index='visit_id', columns='UniProt', values='NPX')\n",
    "    protein_pivot = protein_pivot.reset_index()\n",
    "    \n",
    "    p_id, v_id = zip(*(v_id.split('_') for v_id in protein_pivot.visit_id.values))\n",
    "    proteins = protein_pivot\n",
    "    proteins.insert(1, 'patient_id', np.array(p_id).astype('int32'))\n",
    "    proteins.insert(2, 'visit_month', np.array(v_id).astype('int32'))\n",
    "    print('pivoted and merged')\n",
    "    \n",
    "    # Impute missing values\n",
    "    if proteins.isna().sum().sum() > 0:\n",
    "        protein_lr = lin_reg_imputation(proteins, complete=True)\n",
    "        print('imputed')\n",
    "        print(protein_lr.isna().sum().sum())\n",
    "    else:\n",
    "        protein_lr = proteins\n",
    "    \n",
    "    # Scale protein NPX values\n",
    "    columns = protein_lr.columns\n",
    "    sc = scaler\n",
    "    protein_lr = pd.DataFrame(sc.transform(protein_lr.iloc[:,3:]), columns=columns[3:])\n",
    "    protein_lr = pd.concat([proteins.iloc[:,:3], protein_lr], axis=1)\n",
    "    print('scaled')\n",
    "    \n",
    "    # Reshape for LSTM\n",
    "    months = [0,6,12,18,24,36,48,60,72,84]\n",
    "    num_proteins=len(uniprot_ids)\n",
    "    shown = months[:shown+1]\n",
    "    X_iter = []\n",
    "    sample_info = []\n",
    "    for patient_id, group in protein_lr.groupby('patient_id'):\n",
    "        X_iter.append([])\n",
    "        sample_info.append(patient_id)\n",
    "        verify_month = shown[-1] in group.visit_month.values\n",
    "        for month in months:\n",
    "            if month in shown and month in group.visit_month.values.astype('int'):\n",
    "                X_iter[-1].append(*group[group.visit_month==month].iloc[:,3:].values)\n",
    "            else:\n",
    "                X_iter[-1].append(np.full(num_proteins,-1))\n",
    "    X = np.array(X_iter)\n",
    "    print('reshaped')\n",
    "    \n",
    "    if concat:\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        print('concatenated')\n",
    "        \n",
    "    return X, sample_info, verify_month\n",
    "\n",
    "\n",
    "def train_data_prep(clinical, proteins, concat=True):\n",
    "    \n",
    "    # Modify protein shape\n",
    "    protein_pivot = df_train_proteins.pivot(index='visit_id', columns='UniProt', values='NPX')\n",
    "    protein_pivot = protein_pivot.reset_index()\n",
    "    print('pivoted')\n",
    "    \n",
    "    # Merge with UPDRS scores and remove medication state column\n",
    "    updrs_protein = pd.merge(clinical.drop(['upd23b_clinical_state_on_medication'], axis=1), \n",
    "                             protein_pivot, \n",
    "                             on=['visit_id'])\n",
    "    print('merged')\n",
    "    \n",
    "    # Impute missing values\n",
    "    protein_data = updrs_protein.drop(['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)\n",
    "    protein_lr = lin_reg_imputation(protein_data, complete=True)\n",
    "    print('imputed')\n",
    "    \n",
    "    # Scale protein NPX values\n",
    "    columns = protein_lr.columns\n",
    "    sc = StandardScaler()\n",
    "    protein_lr = pd.DataFrame(sc.fit_transform(protein_lr.iloc[:,3:]), columns=columns[3:])\n",
    "    protein_lr = pd.concat([updrs_protein.iloc[:,:7], protein_lr], axis=1)\n",
    "    print('scaled')\n",
    "    \n",
    "    # Remove useless rows from train data\n",
    "    updrs_subset = protein_lr.iloc[:,:7]\n",
    "    for month in (3,30,54,96,108):\n",
    "        protein_lr.drop(protein_lr[protein_lr.visit_month == month].index, inplace=True)\n",
    "    print('removed rows from protein_lr')\n",
    "    \n",
    "    # Reshape X and Y data for LSTM\n",
    "    X_iter = []\n",
    "    months = [0,6,12,18,24,36,48,60,72,84]\n",
    "    num_proteins=227\n",
    "    for i in range(len(months)):\n",
    "        shown = months[:i+1]\n",
    "        X_iter.append([])\n",
    "        for patien_id, group in protein_lr.groupby('patient_id'):\n",
    "            X_iter[-1].append([])\n",
    "            for month in months:\n",
    "                if month in shown and month in group.visit_month.values:\n",
    "                    X_iter[-1][-1].append(*group[group.visit_month==month].iloc[:,7:].values)\n",
    "                else:\n",
    "                    X_iter[-1][-1].append(np.full(227,-1))\n",
    "\n",
    "    Y_iter = []\n",
    "    for i,month in enumerate(months):\n",
    "        shown = months[:i+1]\n",
    "        Y_iter.append([])\n",
    "        for patient_id, group in updrs_subset.groupby('patient_id'):\n",
    "            Y_iter[-1].append([])\n",
    "            for month2 in [month, month+6, month+12, month+24]:\n",
    "                if month2 in group.visit_month.values:\n",
    "                    if group.isna().sum().sum() >0:\n",
    "                        group.fillna(value=-1, inplace=True)\n",
    "                    Y_iter[-1][-1].append(*group[group.visit_month==month2].iloc[:,3:].values)\n",
    "\n",
    "                else:\n",
    "                    Y_iter[-1][-1].append(np.full(4,-1))\n",
    "\n",
    "    X = np.array(X_iter)\n",
    "    Y = np.array(Y_iter)\n",
    "    print(f'Reshaped\\nX:{X.shape}\\nY:{Y.shape}')\n",
    "    \n",
    "    # Split Y into 4, one for each UPDRS\n",
    "    Y1, Y2, Y3, Y4 = np.split(Y, [1,2,3], axis=3)\n",
    "    for i,data in enumerate([Y1, Y2, Y3, Y4]):\n",
    "        print(f'UPDRS {i+1} shape: {data.shape}')\n",
    "              \n",
    "    if concat:\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        Y1 = np.concatenate(Y1, axis=0)\n",
    "        Y2 = np.concatenate(Y2, axis=0)\n",
    "        Y3 = np.concatenate(Y3, axis=0)\n",
    "        Y4 = np.concatenate(Y4, axis=0)\n",
    "    \n",
    "    return X, [Y1, Y2, Y3, Y4], sc\n",
    "    \n",
    "\n",
    "def SMAPE(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the Symmetric Mean Absolute Percentage Error (SMAPE) loss between y_true and y_pred.\n",
    "    \"\"\"\n",
    "    mask = y_true!=-1\n",
    "    y_pred = y_pred*kb.cast(mask,tf.float32)\n",
    "    y_true = y_true*kb.cast(mask,tf.float32)\n",
    "    \n",
    "    # Comment out later\n",
    "    # y_pred = y_pred+1\n",
    "    # y_true = y_true+1\n",
    "\n",
    "    epsilon = 0.1\n",
    "    summ = kb.maximum(kb.abs(y_true) + kb.abs(y_pred) + epsilon, 0.5+epsilon)\n",
    "    # summ = kb.abs(y_true) + kb.abs(y_pred)\n",
    "    smape = kb.mean(kb.abs(y_pred - y_true) / summ * 2)\n",
    "    return smape*100\n",
    "\n",
    "\n",
    "def round_min_zero(nums):\n",
    "    nums = np.around(nums).astype(int)\n",
    "    return np.maximum(0,nums)\n",
    "\n",
    "\n",
    "def check_smape(y_pred, y_true):\n",
    "    y_pred = round_min_zero(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(y_pred.shape)\n",
    "    mask = y_true!=-1\n",
    "    y_pred = y_pred*mask +1\n",
    "    y_true = y_pred*mask +1\n",
    "    \n",
    "    summ = np.abs(y_pred) + np.abs(y_true)\n",
    "    smape = np.mean(np.abs(y_pred-y_true) / summ *2)\n",
    "    return smape*100\n",
    "\n",
    "\n",
    "def sequential_model(input_shape, concat=True):\n",
    "    print(SMAPE)\n",
    "    if concat:\n",
    "        shape = input_shape[1:]\n",
    "    else:\n",
    "        shape = input_shape[2:]\n",
    "\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(layers.Masking(mask_value=-1, input_shape=shape))\n",
    "    lstm_model.add(layers.Conv1D(16,2,padding='same'))\n",
    "    lstm_model.add(layers.LSTM(64))\n",
    "    lstm_model.add(layers.Dense(4))\n",
    "    lstm_model.compile(loss=SMAPE, optimizer='adam')\n",
    "    lstm_model.summary()\n",
    "    return lstm_model\n",
    "\n",
    "\n",
    "#def API_model(input_shape, concat=True):\n",
    "#    if concat:\n",
    "#        shape = input_shape[1:]\n",
    "#    else:\n",
    "#        shape = input_shape[2:]\n",
    "#    \n",
    "#    inputs = layers.Input(shape)\n",
    "#    mask = layers.Masking(mask_value=-1).compute_mask(inputs)\n",
    "#    conv = layers.Conv1D(16,2,padding='same')(inputs)\n",
    "#    lstm = layers.LSTM(64)(conv, mask=mask)\n",
    "#    out = layers.Dense(4)(lstm)\n",
    "#    model = Model(inputs,out)\n",
    "#    model.compile(loss=SMAPE, optimizer='adam')\n",
    "#    model.summary()\n",
    "#    return model\n",
    "\n",
    "\n",
    "def test_models(model_func, X_data, Y_data, eps=50, batch=16, kfold=None, test_size=0.2, concat=True):\n",
    "    scores = []\n",
    "    X_ftrain, X_ftest, Y_ftrain, Y_ftest = train_test_split(X_data, Y_data, shuffle=True, test_size=test_size)\n",
    "    model = model_func(X_ftrain.shape)\n",
    "    if kfold:\n",
    "        kf = KFold(n_splits=kfold, shuffle=True)\n",
    "        for train_index, test_index in kf.split(X_ftrain, Y_ftrain):\n",
    "            X_train, X_test = X_ftrain[train_index], X_ftrain[test_index]\n",
    "            Y_train, Y_test = Y_ftrain[train_index], Y_ftrain[test_index]\n",
    "            model.fit(X_train,Y_train, epochs=eps, batch_size=batch)\n",
    "            scores.append(check_smape(model.predict(X_test),Y_test))\n",
    "        scores.append(check_smape(model.predict(X_ftest),Y_ftest))\n",
    "    else:\n",
    "        model.fit(X_ftrain,Y_ftrain, epochs=eps, batch_size=batch)\n",
    "        scores.append(check_smape(model.predict(X_ftest),Y_ftest))\n",
    "    return model, scores\n",
    "\n",
    "\n",
    "def train_models(model_func, X_data, Y_data, eps=50, batch=16, kfold=None, test_size=0.2, concat=True):\n",
    "    scores = []\n",
    "    model = model_func(X_data.shape)\n",
    "    if kfold:\n",
    "        kf = KFold(n_splits=kfold, shuffle=True)\n",
    "        for train_index, test_index in kf.split(X_data, Y_data):\n",
    "            X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "            Y_train, Y_test = Y_data[train_index], Y_data[test_index]\n",
    "            model.fit(X_train,Y_train, epochs=eps, batch_size=batch)\n",
    "            scores.append(check_smape(model.predict(X_test),Y_test))\n",
    "    else:\n",
    "        model.fit(X_data,Y_data, epochs=eps, batch_size=batch)\n",
    "        scores.append(check_smape(model.predict(X_data),Y_data))\n",
    "    return model, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84660567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:20:53.250373Z",
     "iopub.status.busy": "2023-05-06T22:20:53.249966Z",
     "iopub.status.idle": "2023-05-06T22:20:53.274504Z",
     "shell.execute_reply": "2023-05-06T22:20:53.273363Z"
    },
    "papermill": {
     "duration": 0.031963,
     "end_time": "2023-05-06T22:20:53.277273",
     "exception": false,
     "start_time": "2023-05-06T22:20:53.245310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Need list of proteins in train in case extra proteins in test API\n",
    "train_uniprot_ids = set(df_train_proteins.UniProt.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ba1ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:20:53.286194Z",
     "iopub.status.busy": "2023-05-06T22:20:53.285817Z",
     "iopub.status.idle": "2023-05-06T22:21:26.080447Z",
     "shell.execute_reply": "2023-05-06T22:21:26.079261Z"
    },
    "papermill": {
     "duration": 32.805366,
     "end_time": "2023-05-06T22:21:26.086379",
     "exception": false,
     "start_time": "2023-05-06T22:20:53.281013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pivoted\n",
      "merged\n",
      "imputed\n",
      "scaled\n",
      "removed rows from protein_lr\n",
      "Reshaped\n",
      "X:(10, 248, 10, 227)\n",
      "Y:(10, 248, 4, 4)\n",
      "UPDRS 1 shape: (10, 248, 4, 1)\n",
      "UPDRS 2 shape: (10, 248, 4, 1)\n",
      "UPDRS 3 shape: (10, 248, 4, 1)\n",
      "UPDRS 4 shape: (10, 248, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y, scaler_object = train_data_prep(df_train_clinical, df_train_proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5dc6c52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:21:26.096264Z",
     "iopub.status.busy": "2023-05-06T22:21:26.095584Z",
     "iopub.status.idle": "2023-05-06T22:21:26.100658Z",
     "shell.execute_reply": "2023-05-06T22:21:26.099636Z"
    },
    "papermill": {
     "duration": 0.012432,
     "end_time": "2023-05-06T22:21:26.102728",
     "exception": false,
     "start_time": "2023-05-06T22:21:26.090296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for y in Y:\n",
    "#    sequential_split = train_model(sequential_model, X, y)\n",
    "#    sequential_kf3 = train_model(sequential_model, X, y, kfold=3)\n",
    "#    sequential_kf5 = train_model(sequential_model, X, y, kfold=5)\n",
    "#    api_split = train_model(API_model, X, y)\n",
    "#    api_kf3 = train_model(API_model, X, y, kfold=3)\n",
    "#    api_kf5 = train_model(API_model, X, y, kfold=5)\n",
    "#for i in [sequential_split, sequential_kf3, sequential_kf5, api_split, api_kf3, api_kf5]:\n",
    "#    print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a8d99ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:21:26.112342Z",
     "iopub.status.busy": "2023-05-06T22:21:26.111979Z",
     "iopub.status.idle": "2023-05-06T22:32:02.544295Z",
     "shell.execute_reply": "2023-05-06T22:32:02.543466Z"
    },
    "papermill": {
     "duration": 636.439709,
     "end_time": "2023-05-06T22:32:02.546538",
     "exception": false,
     "start_time": "2023-05-06T22:21:26.106829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function SMAPE at 0x7774679025f0>\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                20736     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 3s 8ms/step - loss: 34.5414\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.4792\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.4059\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.0177\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 18.6927\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.2058\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.3529\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.6706\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.3038\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.7358\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8155\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.3933\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.9578\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.3157\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.0424\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.7305\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.6425\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.1694\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.7097\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.6225\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.6179\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.1922\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.0053\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.9132\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.9109\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.7830\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.5576\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.5577\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.4785\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.2577\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 10.2995\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.1249\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.8653\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.0321\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.9617\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.7851\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.6244\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.5389\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.4587\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.4918\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.4496\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 9.3833\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.2424\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.2346\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.2204\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.2580\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.1680\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.1502\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.9505\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.9610\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.0236\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.2936\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.3113\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.9946\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.7679\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.5745\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.5591\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.3538\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.1664\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.9693\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.9521\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.8294\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.7193\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.7159\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.4985\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.3385\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.1618\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.1606\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.1425\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.0244\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.8984\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 8.8689\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.8165\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.7282\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.5719\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.4647\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 8.3508\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2736\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 8.3393\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2265\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.0779\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2322\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2675\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.9399\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.9374\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7529\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.6987\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7468\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.6549\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.6965\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.6077\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.3741\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.4219\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.5086\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3551\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3652\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.2489\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0705\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.1855\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.1972\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.5131\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.9759\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.8139\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.5898\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2071\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.0816\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.8578\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7700\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.5395\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.4465\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3879\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.4906\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.2880\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.2342\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0461\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0620\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.9411\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.9041\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.8982\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7432\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.6978\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7513\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.5629\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.5684\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4320\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2869\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3236\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3354\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3826\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.3519\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1445\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1440\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1854\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1890\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9023\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.0014\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9798\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8921\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9608\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8960\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8416\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.6724\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.7756\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.6425\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.6632\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.6534\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 5.5571\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.6331\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8196\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4826\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "<function SMAPE at 0x7774679025f0>\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_1 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 3s 8ms/step - loss: 42.3222\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 38.8955\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 26.7124\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.7733\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.2678\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.3993\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 25.2120\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.0235\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.4447\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.9683\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.0419\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.7240\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.6103\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.7063\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.4353\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.9718\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.1546\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.1633\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.3818\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.9321\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 21.4941\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.9427\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.7331\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.7790\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.5106\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.5939\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.3700\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.2785\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.1916\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.2269\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.2292\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.8760\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.7829\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.9827\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.6663\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 24.1660\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.8017\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.2378\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.0387\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.1714\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.6002\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.7537\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.5613\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.2671\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.2256\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.6188\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.6371\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.4542\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.9332\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.5265\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.5427\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.8682\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.1721\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.9364\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.3112\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.2265\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.1783\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.4808\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.1641\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.0063\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.1668\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.1430\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.0218\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.5203\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.7955\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.7084\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.5436\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.4893\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.5822\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.1297\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.2985\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.2183\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.7982\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.2318\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.0826\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.0614\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.9730\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.0874\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.3240\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.3912\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.2056\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.2185\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.2041\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8239\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8671\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.5601\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.3318\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8811\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.3344\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.9061\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 14.4427\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 13.4792\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.5544\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.1057\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.1591\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.0862\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.3226\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.9294\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8386\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.1152\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.1391\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.3089\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.8221\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.3680\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 13.3089\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.0526\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9212\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.7937\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9536\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 12.7589\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.4879\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.3479\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.2541\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.0835\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.9042\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.8003\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.4519\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.0291\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.8011\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.5988\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.3279\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.2891\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.6192\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.2832\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.8526\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.5896\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.2673\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.4736\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.1334\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.2910\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.8841\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.3065\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.1474\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.4751\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.4512\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.0779\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.0736\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.9933\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.4282\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.0355\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.5971\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.4486\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.3114\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.1955\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.0140\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.6401\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.7090\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.8144\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.3043\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.7584\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "<function SMAPE at 0x7774679025f0>\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_2 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 3s 8ms/step - loss: 47.0492\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 46.3977\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 41.6191\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 35.3326\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 29.4944\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 26.7702\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 26.1095\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 24.7454\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 24.6012\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.9942\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 24.4163\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.9683\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.7968\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.3989\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.1036\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.2831\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.2125\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.1458\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.8948\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.6958\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.8913\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.9439\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.7175\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.4486\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 26.8831\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 25.4748\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 25.7019\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 26.0190\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 24.2420\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.0723\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.2037\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.2390\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.1124\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.6079\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 21.3987\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.3633\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.4137\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.4485\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.3111\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.0442\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.4498\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.3344\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.2394\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.5943\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 24.1956\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.0798\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.2555\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.7631\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.5878\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.3493\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.3393\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.1305\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.9849\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.7576\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.6343\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.5112\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.2547\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.4037\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.9067\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.7071\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.2889\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.3972\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.9598\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.7242\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.5272\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.5200\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.7968\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.3693\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.3986\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.1733\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.1882\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.9688\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.9335\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.7576\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.5628\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5331\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.3989\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.3371\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.4868\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.1470\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.9398\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8900\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.9308\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8387\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.6975\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.7659\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.1664\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.9342\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.0164\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.7640\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.9816\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.7933\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.4319\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.5365\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8636\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.0115\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.2736\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8668\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8625\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.5394\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.5385\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.2203\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8243\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.4426\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.3854\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.3707\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.1732\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.1933\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.8304\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.7207\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.6281\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.5637\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 13.6815\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.3154\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.1594\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9676\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9136\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.8085\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.7554\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.1378\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.1161\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9612\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.7982\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.6425\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.0934\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.7884\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.8026\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.2176\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.6708\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.8474\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.4114\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.1318\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.1306\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9720\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.1288\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9773\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.8986\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.8277\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.1793\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9413\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.8481\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.8657\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.8217\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.6772\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.5709\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.5448\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.5257\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.5295\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.4894\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 12.8480\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "<function SMAPE at 0x7774679025f0>\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_3 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 3s 9ms/step - loss: 13.8354\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.4727\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.3901\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.2664\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.9939\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.6188\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.3276\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.6419\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.0551\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.5302\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.0945\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.5308\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.2439\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.5831\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.4356\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.1940\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.6923\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2736\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2123\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.5104\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.0922\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7665\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7988\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.0551\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.5834\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.3819\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3904\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0925\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.1726\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.2030\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.9022\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 7.0900\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7016\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.5191\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3358\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4174\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1990\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4203\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.7271\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2840\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1151\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9410\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9636\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9298\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8595\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.8536\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.7260\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8018\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8007\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8347\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.5436\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3288\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.7600\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.6196\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2898\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0645\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.9054\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.7933\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 6.2417\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2431\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0518\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4323\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.8199\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8585\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.9717\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.7445\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3059\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3433\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.2295\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.2855\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.2322\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.1514\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.1095\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9949\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9492\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9391\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.0013\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9059\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9042\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9104\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9159\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.8033\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7718\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.8161\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7442\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7456\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.6975\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7377\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7146\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7285\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7216\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7850\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7277\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4408\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.0152\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.0897\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3712\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9115\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.4121\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.0489\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.8586\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9373\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.7167\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.5462\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.1649\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.2345\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.0180\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.5982\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.8049\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4654\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2174\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8902\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3824\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3766\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.2548\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4184\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3836\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.1489\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9895\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9319\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.8053\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.8845\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.8054\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.9745\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.8839\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.8264\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7259\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.8056\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9221\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.2323\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.0107\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.1815\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.2224\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.7661\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.5313\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.4692\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.4352\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.3789\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.3134\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.2882\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.2397\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.2153\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.1697\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.2109\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.1824\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.1001\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.0885\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.0730\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.1165\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.1196\n",
      "26/26 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "trained_model, scores = zip(*[train_models(sequential_model, X, y, kfold=3) for y in Y])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b0ee3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:32:03.922047Z",
     "iopub.status.busy": "2023-05-06T22:32:03.921367Z",
     "iopub.status.idle": "2023-05-06T22:32:03.926754Z",
     "shell.execute_reply": "2023-05-06T22:32:03.925623Z"
    },
    "papermill": {
     "duration": 0.729211,
     "end_time": "2023-05-06T22:32:03.928613",
     "exception": false,
     "start_time": "2023-05-06T22:32:03.199402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <keras.engine.sequential.Sequential object at 0x77745d633cd0>\n",
      "scores: [5.0285606829835485, 4.909845610930271, 5.253072577494464]\n",
      "\n",
      "model: <keras.engine.sequential.Sequential object at 0x7774654f7400>\n",
      "scores: [5.744011976917922, 8.027520747691613, 8.87706577109206]\n",
      "\n",
      "model: <keras.engine.sequential.Sequential object at 0x7774672e69b0>\n",
      "scores: [3.4500253641102994, 4.487031470840175, 3.497813552154616]\n",
      "\n",
      "model: <keras.engine.sequential.Sequential object at 0x77746701cfa0>\n",
      "scores: [8.365370219436352, 9.966388596597378, 8.968485157908388]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(f'model: {trained_model[i]}\\nscores: {scores[i]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59a6297f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:32:05.230701Z",
     "iopub.status.busy": "2023-05-06T22:32:05.229960Z",
     "iopub.status.idle": "2023-05-06T22:32:05.238001Z",
     "shell.execute_reply": "2023-05-06T22:32:05.237266Z"
    },
    "papermill": {
     "duration": 0.665708,
     "end_time": "2023-05-06T22:32:05.240051",
     "exception": false,
     "start_time": "2023-05-06T22:32:04.574343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_submission_df(predictions, ids, loop):\n",
    "    updrs_list = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']\n",
    "    months = [0,6,12,18,24,36,48,60,72,84]\n",
    "    month = months[loop]\n",
    "    plus_list = [0,6,12,24]\n",
    "    \n",
    "    prediction_ids = []\n",
    "    \n",
    "    all_predictions = round_min_zero(predictions)\n",
    "    for i,preds in enumerate(all_predictions):\n",
    "        patient = 0\n",
    "        prediction_ids.append([])\n",
    "        preds = preds.reshape(4*len(preds))\n",
    "        for j,pred in enumerate(preds):\n",
    "            plus_month = plus_list[j%4]\n",
    "            prediction_ids[-1].append('_'.join([str(ids[patient]),str(month),updrs_list[i], 'plus', str(plus_month), 'months']))\n",
    "            patient += (j%4+1)//4\n",
    "    \n",
    "    dfs = []\n",
    "    for pred_ids, pred in zip(prediction_ids, all_predictions):\n",
    "        pred = pred.reshape(4*len(pred))\n",
    "        pred_ids = np.array(pred_ids)\n",
    "        dfs.append(pd.DataFrame({'prediction_id':pred_ids, 'rating':pred}).set_index('prediction_id'))\n",
    "\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ad6e1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:32:06.646638Z",
     "iopub.status.busy": "2023-05-06T22:32:06.645923Z",
     "iopub.status.idle": "2023-05-06T22:32:06.684045Z",
     "shell.execute_reply": "2023-05-06T22:32:06.683243Z"
    },
    "papermill": {
     "duration": 0.69778,
     "end_time": "2023-05-06T22:32:06.686449",
     "exception": false,
     "start_time": "2023-05-06T22:32:05.988669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import amp_pd_peptide_310\n",
    "env = amp_pd_peptide_310.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c67d416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:32:08.054203Z",
     "iopub.status.busy": "2023-05-06T22:32:08.053482Z",
     "iopub.status.idle": "2023-05-06T22:32:08.758665Z",
     "shell.execute_reply": "2023-05-06T22:32:08.757073Z"
    },
    "papermill": {
     "duration": 1.356945,
     "end_time": "2023-05-06T22:32:08.760586",
     "exception": true,
     "start_time": "2023-05-06T22:32:07.403641",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'method' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (test, test_peptides, test_proteins, sample_submission) \u001b[38;5;129;01min\u001b[39;00m iter_test:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_proteins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([data, pd\u001b[38;5;241m.\u001b[39mread_csv(test_proteins)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:704\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    701\u001b[0m errors \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;00m\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_binary_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    705\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# validate encoding and errors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:1163\u001b[0m, in \u001b[0;36m_is_binary_mode\u001b[0;34m(handle, mode)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(handle), text_classes):\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, _get_binary_io_classes()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'method' is not iterable"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "loop = 0\n",
    "for (test, test_peptides, test_proteins, sample_submission) in iter_test:\n",
    "    if loop == 0:\n",
    "        data = pd.read_csv(test_proteins)\n",
    "    else:\n",
    "        data = pd.concat([data, pd.read_csv(test_proteins)], axis=0)\n",
    "    test_input, test_patients, correct_month = test_data_prep(data, train_uniprot_ids, scaler_object)\n",
    "    print(correct_month)\n",
    "    \n",
    "    # Double and Triple check that data is fully imputed aka no nan values\n",
    "    if test_input.isna().sum().sum() > 0:\n",
    "        test_input.fillna(data.mean(), inplace=True)\n",
    "        print('column mean imputation required')\n",
    "    if test_input.isna().sum().sum() > 0:\n",
    "        test_input.fillna(0, inplace=True)\n",
    "        print('zero imputation required')\n",
    "        print(test_input.head(10))\n",
    "    print(test_input.shape)\n",
    "    \n",
    "    temp_results = [model.predict(test_input) for model in trained_model]\n",
    "    \n",
    "    \n",
    "    sample_submission = create_submission_df(temp_results, test_patients, loop)\n",
    "    \n",
    "    \n",
    "    # final line, outputs csv for submission. Need to pass in a dataframe.\n",
    "    # columns are prediction_id and rating\n",
    "    env.predict(sample_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 700.037893,
   "end_time": "2023-05-06T22:32:12.430883",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-06T22:20:32.392990",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
