{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ef0311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T02:35:47.539259Z",
     "iopub.status.busy": "2023-05-07T02:35:47.538748Z",
     "iopub.status.idle": "2023-05-07T02:35:57.464269Z",
     "shell.execute_reply": "2023-05-07T02:35:57.462928Z"
    },
    "papermill": {
     "duration": 9.934583,
     "end_time": "2023-05-07T02:35:57.467863",
     "exception": false,
     "start_time": "2023-05-07T02:35:47.533280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential, Model\n",
    "from tensorflow.keras import backend as kb\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/amp-pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144bf0a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T02:35:57.477259Z",
     "iopub.status.busy": "2023-05-07T02:35:57.476482Z",
     "iopub.status.idle": "2023-05-07T02:35:59.193542Z",
     "shell.execute_reply": "2023-05-07T02:35:59.192291Z"
    },
    "papermill": {
     "duration": 1.724937,
     "end_time": "2023-05-07T02:35:59.196662",
     "exception": false,
     "start_time": "2023-05-07T02:35:57.471725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\n",
    "df_train_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\n",
    "df_train_clinical = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3cf36fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T02:35:59.205653Z",
     "iopub.status.busy": "2023-05-07T02:35:59.205270Z",
     "iopub.status.idle": "2023-05-07T02:35:59.251219Z",
     "shell.execute_reply": "2023-05-07T02:35:59.250017Z"
    },
    "papermill": {
     "duration": 0.054124,
     "end_time": "2023-05-07T02:35:59.254256",
     "exception": false,
     "start_time": "2023-05-07T02:35:59.200132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lin_reg(mat):\n",
    "    if mat.shape[0] == 1:\n",
    "        return 0, mat[0,1]\n",
    "    \n",
    "    X = mat[:,0]\n",
    "    X = np.vstack([X, np.ones(len(X))]).T\n",
    "    Y = mat[:,1]\n",
    "    \n",
    "    # res = np.dot(np.linalg.inv(X.T@X)@X.T, Y)            # This might be faster? (Uses pseudoinverse to calculate weights)\n",
    "    res = np.around(np.linalg.lstsq(X,Y, rcond=None)[0])\n",
    "    return res\n",
    "\n",
    "\n",
    "def lin_reg_imputation(df, complete=False, style='mean'):\n",
    "    global t0\n",
    "    # res = [0]*len(df.patient_id.unique())       # To preallocate a list, might be faster?\n",
    "    # i = 0                                       # If using preallocation\n",
    "    res= []\n",
    "    for patient, group in df.groupby('patient_id'):\n",
    "        months = group['visit_month']\n",
    "        for col in group:\n",
    "            data = group[col]\n",
    "            if data.isna().sum() not in (0, len(data)):\n",
    "                m,b = get_lin_reg(pd.concat([months,data], axis=1).dropna().values)\n",
    "                group[col].fillna(m*months + b, inplace=True)\n",
    "        res.append(group)\n",
    "        # res[i] = group                          # If using preallocation\n",
    "        # i += 1                                  # If using preallocation\n",
    "    df_linreg = pd.concat(res)\n",
    "    if complete:\n",
    "        if style=='mean':\n",
    "            df_linreg.fillna(df_linreg.mean(), inplace=True)\n",
    "        elif style=='zero':\n",
    "            df_linreg.fillna(0, inplace=True)\n",
    "        else:\n",
    "            raise Exception(f'\"{style}\" is not a valid imputation method. Available options are \"mean\" or \"zero\"')\n",
    "    return df_linreg\n",
    "\n",
    "\n",
    "def test_data_prep(proteins, uniprot_ids, scaler, shown, concat=True):\n",
    "    \n",
    "    # Remove extra proteins\n",
    "    new_uniprots = set(proteins.UniProt.unique())\n",
    "    extra_prots = new_uniprots.difference(uniprot_ids)\n",
    "    proteins = proteins.drop(extra_prots)\n",
    "    print('removed extras')\n",
    "    print(f'removed {extra_prots}')\n",
    "    \n",
    "    # Reshape\n",
    "    protein_pivot = df_train_proteins.pivot(index='visit_id', columns='UniProt', values='NPX')\n",
    "    protein_pivot = protein_pivot.reset_index()\n",
    "    \n",
    "    p_id, v_id = zip(*(v_id.split('_') for v_id in protein_pivot.visit_id.values))\n",
    "    proteins = protein_pivot\n",
    "    proteins.insert(1, 'patient_id', np.array(p_id).astype('int32'))\n",
    "    proteins.insert(2, 'visit_month', np.array(v_id).astype('int32'))\n",
    "    print('pivoted and merged')\n",
    "    \n",
    "    # Impute missing values\n",
    "    if proteins.isna().sum().sum() > 0:\n",
    "        protein_lr = lin_reg_imputation(proteins, complete=True)\n",
    "        print('imputed')\n",
    "        print(protein_lr.isna().sum().sum())\n",
    "    else:\n",
    "        protein_lr = proteins\n",
    "    \n",
    "    # Scale protein NPX values\n",
    "    columns = protein_lr.columns\n",
    "    sc = scaler\n",
    "    protein_lr = pd.DataFrame(sc.transform(protein_lr.iloc[:,3:]), columns=columns[3:])\n",
    "    protein_lr = pd.concat([proteins.iloc[:,:3], protein_lr], axis=1)\n",
    "    print('scaled')\n",
    "    \n",
    "    # Reshape for LSTM\n",
    "    months = [0,6,12,18,24,36,48,60,72,84]\n",
    "    num_proteins=len(uniprot_ids)\n",
    "    shown = months[:shown+1]\n",
    "    X_iter = []\n",
    "    sample_info = []\n",
    "    for patient_id, group in protein_lr.groupby('patient_id'):\n",
    "        X_iter.append([])\n",
    "        sample_info.append(patient_id)\n",
    "        verify_month = shown[-1] in group.visit_month.values\n",
    "        for month in months:\n",
    "            if month in shown and month in group.visit_month.values.astype('int'):\n",
    "                X_iter[-1].append(*group[group.visit_month==month].iloc[:,3:].values)\n",
    "            else:\n",
    "                X_iter[-1].append(np.full(num_proteins,-1))\n",
    "    X = np.array(X_iter)\n",
    "    print('reshaped')\n",
    "    \n",
    "    if concat:\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        print('concatenated')\n",
    "        \n",
    "    return X, sample_info, verify_month\n",
    "\n",
    "\n",
    "def train_data_prep(clinical, proteins, concat=True):\n",
    "    \n",
    "    # Modify protein shape\n",
    "    protein_pivot = df_train_proteins.pivot(index='visit_id', columns='UniProt', values='NPX')\n",
    "    protein_pivot = protein_pivot.reset_index()\n",
    "    print('pivoted')\n",
    "    \n",
    "    # Merge with UPDRS scores and remove medication state column\n",
    "    updrs_protein = pd.merge(clinical.drop(['upd23b_clinical_state_on_medication'], axis=1), \n",
    "                             protein_pivot, \n",
    "                             on=['visit_id'])\n",
    "    print('merged')\n",
    "    \n",
    "    # Impute missing values\n",
    "    protein_data = updrs_protein.drop(['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)\n",
    "    protein_lr = lin_reg_imputation(protein_data, complete=True)\n",
    "    print('imputed')\n",
    "    \n",
    "    # Scale protein NPX values\n",
    "    columns = protein_lr.columns\n",
    "    sc = StandardScaler()\n",
    "    protein_lr = pd.DataFrame(sc.fit_transform(protein_lr.iloc[:,3:]), columns=columns[3:])\n",
    "    protein_lr = pd.concat([updrs_protein.iloc[:,:7], protein_lr], axis=1)\n",
    "    print('scaled')\n",
    "    \n",
    "    # Remove useless rows from train data\n",
    "    updrs_subset = protein_lr.iloc[:,:7]\n",
    "    for month in (3,30,54,96,108):\n",
    "        protein_lr.drop(protein_lr[protein_lr.visit_month == month].index, inplace=True)\n",
    "    print('removed rows from protein_lr')\n",
    "    \n",
    "    # Reshape X and Y data for LSTM\n",
    "    X_iter = []\n",
    "    months = [0,6,12,18,24,36,48,60,72,84]\n",
    "    num_proteins=227\n",
    "    for i in range(len(months)):\n",
    "        shown = months[:i+1]\n",
    "        X_iter.append([])\n",
    "        for patien_id, group in protein_lr.groupby('patient_id'):\n",
    "            X_iter[-1].append([])\n",
    "            for month in months:\n",
    "                if month in shown and month in group.visit_month.values:\n",
    "                    X_iter[-1][-1].append(*group[group.visit_month==month].iloc[:,7:].values)\n",
    "                else:\n",
    "                    X_iter[-1][-1].append(np.full(227,-1))\n",
    "\n",
    "    Y_iter = []\n",
    "    for i,month in enumerate(months):\n",
    "        shown = months[:i+1]\n",
    "        Y_iter.append([])\n",
    "        for patient_id, group in updrs_subset.groupby('patient_id'):\n",
    "            Y_iter[-1].append([])\n",
    "            for month2 in [month, month+6, month+12, month+24]:\n",
    "                if month2 in group.visit_month.values:\n",
    "                    if group.isna().sum().sum() >0:\n",
    "                        group.fillna(value=-1, inplace=True)\n",
    "                    Y_iter[-1][-1].append(*group[group.visit_month==month2].iloc[:,3:].values)\n",
    "\n",
    "                else:\n",
    "                    Y_iter[-1][-1].append(np.full(4,-1))\n",
    "\n",
    "    X = np.array(X_iter)\n",
    "    Y = np.array(Y_iter)\n",
    "    print(f'Reshaped\\nX:{X.shape}\\nY:{Y.shape}')\n",
    "    \n",
    "    # Split Y into 4, one for each UPDRS\n",
    "    Y1, Y2, Y3, Y4 = np.split(Y, [1,2,3], axis=3)\n",
    "    for i,data in enumerate([Y1, Y2, Y3, Y4]):\n",
    "        print(f'UPDRS {i+1} shape: {data.shape}')\n",
    "              \n",
    "    if concat:\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        Y1 = np.concatenate(Y1, axis=0)\n",
    "        Y2 = np.concatenate(Y2, axis=0)\n",
    "        Y3 = np.concatenate(Y3, axis=0)\n",
    "        Y4 = np.concatenate(Y4, axis=0)\n",
    "    \n",
    "    return X, [Y1, Y2, Y3, Y4], sc\n",
    "    \n",
    "\n",
    "def SMAPE(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the Symmetric Mean Absolute Percentage Error (SMAPE) loss between y_true and y_pred.\n",
    "    \"\"\"\n",
    "    mask = y_true!=-1\n",
    "    y_pred = y_pred*kb.cast(mask,tf.float32)\n",
    "    y_true = y_true*kb.cast(mask,tf.float32)\n",
    "    \n",
    "    # Comment out later\n",
    "    # y_pred = y_pred+1\n",
    "    # y_true = y_true+1\n",
    "\n",
    "    epsilon = 0.1\n",
    "    summ = kb.maximum(kb.abs(y_true) + kb.abs(y_pred) + epsilon, 0.5+epsilon)\n",
    "    # summ = kb.abs(y_true) + kb.abs(y_pred)\n",
    "    smape = kb.mean(kb.abs(y_pred - y_true) / summ * 2)\n",
    "    return smape*100\n",
    "\n",
    "\n",
    "def round_min_zero(nums):\n",
    "    nums = np.around(nums).astype(int)\n",
    "    return np.maximum(0,nums)\n",
    "\n",
    "\n",
    "def check_smape(y_pred, y_true):\n",
    "    y_pred = round_min_zero(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(y_pred.shape)\n",
    "    mask = y_true!=-1\n",
    "    y_pred = y_pred*mask +1\n",
    "    y_true = y_pred*mask +1\n",
    "    \n",
    "    summ = np.abs(y_pred) + np.abs(y_true)\n",
    "    smape = np.mean(np.abs(y_pred-y_true) / summ *2)\n",
    "    return smape*100\n",
    "\n",
    "\n",
    "def sequential_model(input_shape, concat=True):\n",
    "    print(SMAPE)\n",
    "    if concat:\n",
    "        shape = input_shape[1:]\n",
    "    else:\n",
    "        shape = input_shape[2:]\n",
    "\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(layers.Masking(mask_value=-1, input_shape=shape))\n",
    "    lstm_model.add(layers.Conv1D(16,2,padding='same'))\n",
    "    lstm_model.add(layers.LSTM(64))\n",
    "    lstm_model.add(layers.Dense(4))\n",
    "    lstm_model.compile(loss=SMAPE, optimizer='adam')\n",
    "    lstm_model.summary()\n",
    "    return lstm_model\n",
    "\n",
    "\n",
    "#def API_model(input_shape, concat=True):\n",
    "#    if concat:\n",
    "#        shape = input_shape[1:]\n",
    "#    else:\n",
    "#        shape = input_shape[2:]\n",
    "#    \n",
    "#    inputs = layers.Input(shape)\n",
    "#    mask = layers.Masking(mask_value=-1).compute_mask(inputs)\n",
    "#    conv = layers.Conv1D(16,2,padding='same')(inputs)\n",
    "#    lstm = layers.LSTM(64)(conv, mask=mask)\n",
    "#    out = layers.Dense(4)(lstm)\n",
    "#    model = Model(inputs,out)\n",
    "#    model.compile(loss=SMAPE, optimizer='adam')\n",
    "#    model.summary()\n",
    "#    return model\n",
    "\n",
    "\n",
    "def test_models(model_func, X_data, Y_data, eps=50, batch=16, kfold=None, test_size=0.2, concat=True):\n",
    "    scores = []\n",
    "    X_ftrain, X_ftest, Y_ftrain, Y_ftest = train_test_split(X_data, Y_data, shuffle=True, test_size=test_size)\n",
    "    model = model_func(X_ftrain.shape)\n",
    "    if kfold:\n",
    "        kf = KFold(n_splits=kfold, shuffle=True)\n",
    "        for train_index, test_index in kf.split(X_ftrain, Y_ftrain):\n",
    "            X_train, X_test = X_ftrain[train_index], X_ftrain[test_index]\n",
    "            Y_train, Y_test = Y_ftrain[train_index], Y_ftrain[test_index]\n",
    "            model.fit(X_train,Y_train, epochs=eps, batch_size=batch)\n",
    "            scores.append(check_smape(model.predict(X_test),Y_test))\n",
    "        scores.append(check_smape(model.predict(X_ftest),Y_ftest))\n",
    "    else:\n",
    "        model.fit(X_ftrain,Y_ftrain, epochs=eps, batch_size=batch)\n",
    "        scores.append(check_smape(model.predict(X_ftest),Y_ftest))\n",
    "    return model, scores\n",
    "\n",
    "\n",
    "def train_models(model_func, X_data, Y_data, eps=50, batch=16, kfold=None, test_size=0.2, concat=True):\n",
    "    scores = []\n",
    "    model = model_func(X_data.shape)\n",
    "    if kfold:\n",
    "        kf = KFold(n_splits=kfold, shuffle=True)\n",
    "        for train_index, test_index in kf.split(X_data, Y_data):\n",
    "            X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "            Y_train, Y_test = Y_data[train_index], Y_data[test_index]\n",
    "            model.fit(X_train,Y_train, epochs=eps, batch_size=batch)\n",
    "            scores.append(check_smape(model.predict(X_test),Y_test))\n",
    "    else:\n",
    "        model.fit(X_data,Y_data, epochs=eps, batch_size=batch)\n",
    "        scores.append(check_smape(model.predict(X_data),Y_data))\n",
    "    return model, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e54bc79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T02:35:59.262968Z",
     "iopub.status.busy": "2023-05-07T02:35:59.262574Z",
     "iopub.status.idle": "2023-05-07T02:35:59.288132Z",
     "shell.execute_reply": "2023-05-07T02:35:59.286773Z"
    },
    "papermill": {
     "duration": 0.033689,
     "end_time": "2023-05-07T02:35:59.291471",
     "exception": false,
     "start_time": "2023-05-07T02:35:59.257782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Need list of proteins in train in case extra proteins in test API\n",
    "train_uniprot_ids = set(df_train_proteins.UniProt.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2c9b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T02:35:59.301108Z",
     "iopub.status.busy": "2023-05-07T02:35:59.300673Z",
     "iopub.status.idle": "2023-05-07T02:36:35.132696Z",
     "shell.execute_reply": "2023-05-07T02:36:35.131130Z"
    },
    "papermill": {
     "duration": 35.841642,
     "end_time": "2023-05-07T02:36:35.137277",
     "exception": false,
     "start_time": "2023-05-07T02:35:59.295635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pivoted\n",
      "merged\n",
      "imputed\n",
      "scaled\n",
      "removed rows from protein_lr\n",
      "Reshaped\n",
      "X:(10, 248, 10, 227)\n",
      "Y:(10, 248, 4, 4)\n",
      "UPDRS 1 shape: (10, 248, 4, 1)\n",
      "UPDRS 2 shape: (10, 248, 4, 1)\n",
      "UPDRS 3 shape: (10, 248, 4, 1)\n",
      "UPDRS 4 shape: (10, 248, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y, scaler_object = train_data_prep(df_train_clinical, df_train_proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec23cca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T02:36:35.146737Z",
     "iopub.status.busy": "2023-05-07T02:36:35.146354Z",
     "iopub.status.idle": "2023-05-07T03:09:46.832304Z",
     "shell.execute_reply": "2023-05-07T03:09:46.830896Z"
    },
    "papermill": {
     "duration": 1993.697915,
     "end_time": "2023-05-07T03:09:48.839122",
     "exception": false,
     "start_time": "2023-05-07T02:36:35.141207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                20736     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 7ms/step - loss: 30.0500\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.4440\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.1585\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.6549\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.2532\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.9454\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.3065\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.2255\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.4036\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.1474\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 15.5069\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 14.8815\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.5242\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.8951\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 13.6245\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.2769\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.9579\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.8873\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.4425\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.0704\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.0084\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.6499\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.3781\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.2396\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.1598\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.0118\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8642\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.6818\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.6743\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.5642\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.4932\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.3639\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.1919\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2307\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.0845\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9233\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8988\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8317\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8161\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7272\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5614\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5135\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5181\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3599\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3933\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2039\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2225\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2186\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.1032\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9851\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_1 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 3s 8ms/step - loss: 34.0257\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.0131\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.9266\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.7932\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.4936\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.8019\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.2166\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.1410\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.3422\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.8358\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.3140\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.6108\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.0996\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.6997\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.3003\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9147\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.6335\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.3410\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.9868\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.8544\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.6091\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.4089\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.3480\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.1757\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.0602\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.9812\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.7871\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.9691\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.6870\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.5020\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.3542\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.3942\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.2069\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.0703\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.9761\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.9274\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.8370\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.9698\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.7470\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.6139\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.4876\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.6553\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.3396\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.3283\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.2180\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.2620\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.2261\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.1195\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.0658\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.9681\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.2455\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.7592\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.4070\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.1646\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.0193\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.8553\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.7011\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.6332\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.6231\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.4445\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.3155\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.1204\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.1383\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.0069\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.8726\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.7908\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.7867\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.6685\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.5247\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.4611\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.3323\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.3163\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.1889\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2205\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.1274\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.1749\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.9470\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.9129\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.8672\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7876\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7166\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7102\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.5800\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.4719\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.4679\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3994\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3046\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.2611\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.2548\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.1269\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0769\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0432\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0267\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.9376\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.9979\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.9736\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0545\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0201\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7744\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7662\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.6474\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.1894\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.9405\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.6504\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.5539\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2888\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.3163\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.1384\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.9760\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.8112\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7036\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.5958\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.5126\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3804\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3461\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.3636\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.1350\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.2177\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0942\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0800\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.9760\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.8968\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7050\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7735\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7098\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.5815\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.6485\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.5022\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3516\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.6012\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3935\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3691\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3425\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2722\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1505\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1852\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2169\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2069\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0631\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1132\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.9390\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9844\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9784\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9170\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1977\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.0238\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9003\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8641\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.7140\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.7373\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_2 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 8ms/step - loss: 30.6046\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.7640\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.4463\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.0313\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.2530\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.4794\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.5842\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.9510\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.1393\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.7118\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.2466\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.6969\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.4406\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.0133\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.0113\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.6761\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.5133\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 12.1543\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.9775\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.7111\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.6117\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.5091\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.2658\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.1466\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 10.9949\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 10.8858\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 10.7238\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 10.7844\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.6930\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.5675\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2973\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.1783\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 10.1103\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 10.1744\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9138\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8375\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7559\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6349\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6341\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5368\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.4003\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3305\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2787\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.2537\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2485\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0611\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9302\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9925\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.9059\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8216\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8713\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5071\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2884\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.0577\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9972\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9034\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9703\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7311\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6769\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5705\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6471\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.4332\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3130\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3278\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3189\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2323\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1736\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0908\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0409\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9515\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8872\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7927\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.8282\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6821\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6883\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6274\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6425\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4769\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4748\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3740\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3601\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2152\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2668\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.1822\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.1751\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0836\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9854\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9874\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.9258\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8468\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8491\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8098\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8408\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.7253\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.7264\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.6183\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.5093\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.5682\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.5222\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.4285\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9123\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6406\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5101\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3066\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.1681\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0749\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8851\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8853\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8283\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.7744\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.5763\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.6554\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.5439\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.5050\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.5367\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.3665\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.3482\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.3226\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.1973\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.1796\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.0581\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.0006\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.0634\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.9059\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.8982\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.9194\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.8416\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.6894\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.6378\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.6536\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.5859\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.5604\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.5756\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.5421\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.5239\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4569\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4795\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.3635\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4676\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4730\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2304\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1823\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1938\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1155\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1894\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0423\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0841\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0060\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0630\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0365\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.2896\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.0287\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.9344\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.8996\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.8026\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.6622\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.6061\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.5949\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.5153\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4241\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2773\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4651\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2952\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.3634\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.3217\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.3015\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2457\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1439\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0866\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0855\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0832\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0196\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0027\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9383\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9962\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9154\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9167\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9817\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.9512\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.8754\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.8634\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9049\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.8180\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.8309\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.7763\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7819\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7352\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7328\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6608\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6958\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6588\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6718\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6405\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6339\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6095\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6745\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6217\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6072\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5301\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5764\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0422\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0399\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9246\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.8088\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7257\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.7086\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5756\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5756\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5159\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5318\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4638\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4903\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4659\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3905\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4225\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4226\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4080\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3897\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3477\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2902\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2492\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2567\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3007\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1652\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2356\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2119\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1260\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1227\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0903\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1346\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1071\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0604\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0517\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0363\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 3.9246\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0888\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9624\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9515\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.8883\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9739\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9182\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 3.9391\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9245\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.8377\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.8160\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.8137\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.8094\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.8000\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.7868\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.7694\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_3 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 7ms/step - loss: 43.4265\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 35.4994\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 27.4861\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 26.1430\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.2884\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.6654\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.9394\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.4978\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.4983\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.7084\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.7676\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.7109\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.9981\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.6817\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 25.6670\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 27.9973\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 26.0461\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.6340\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.1011\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.6710\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.8393\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.8459\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.3867\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.0347\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.9607\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.2731\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.7989\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.5884\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.4991\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.1047\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.8083\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 20.9391\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.3372\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.8489\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.5885\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.3705\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.2808\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.0283\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.2793\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.8267\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.7672\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.2830\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.7622\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.6256\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.2413\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.0392\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.3075\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.6110\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.3901\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.3525\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_4 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 3s 8ms/step - loss: 43.2915\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 35.4812\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 26.2196\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 25.7763\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.9660\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.3477\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.1885\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.6870\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.0863\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.7587\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.0534\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.9283\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.4176\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.9348\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.5193\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.5573\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.5980\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.6882\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.8676\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.7994\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.2560\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.7124\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.9196\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.8291\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.8826\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.2233\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.9015\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.4972\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.5787\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.1017\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 17.7582\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.3997\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.3467\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.0632\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.8917\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.0578\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.7038\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.4909\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.2186\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.5903\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.7058\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.0377\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5162\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.4501\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.2773\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.3725\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.0398\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.3037\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.3446\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.3397\n",
      "26/26 [==============================] - 1s 5ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 18.5979\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.5293\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.6312\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.2800\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.1503\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.8134\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5630\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.4662\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5779\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.6779\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.1116\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.2270\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.6263\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 14.7936\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.7312\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.5845\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.7145\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 13.7844\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.0424\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.8517\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 12.7840\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 12.3601\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 12.0695\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 11ms/step - loss: 11.8913\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 11.8628\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 11.9348\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.9836\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.6254\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.4386\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.8191\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.7589\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.3805\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.1082\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.0940\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.6812\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.6927\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.4549\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.0475\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.9832\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.2366\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.0507\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.8723\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.9621\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.1626\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.6671\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.3719\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.2596\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.1501\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.9631\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.7820\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.5770\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5971\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.4964\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.0822\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.0451\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.6915\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.7894\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.6058\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.1414\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 10.4948\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.3862\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.3229\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.8727\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.7257\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.4961\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.5525\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.2325\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.3167\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.3138\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.1725\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.1566\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.2332\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.0621\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.1745\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.1622\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.1445\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.1627\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.0148\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.5106\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.3497\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.1576\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.0213\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.2551\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.1479\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.0254\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.9717\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.7429\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.9279\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.9460\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.8760\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 8.8673\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.1064\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.3689\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.3102\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.4950\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.6397\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.2590\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.8771\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.2276\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.9241\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_5 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 7ms/step - loss: 42.9519\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 31.1870\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 26.4376\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.6190\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.3486\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.5730\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.0125\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.9654\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 21.7883\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 20.9054\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.7071\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.0751\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.2799\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.3667\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.1050\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.6089\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 19.8951\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.4577\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.0898\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.7625\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 20.6688\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.9289\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.7175\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 19.3585\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.0035\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.7751\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.4953\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.5416\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.1168\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.1900\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.9622\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 17.9307\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.5735\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 18.8181\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.9699\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.0311\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.6432\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.3422\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.2744\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.7165\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.0464\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.9002\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 18.4519\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 17.9469\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.3404\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.7205\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.6351\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.5892\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.3804\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.2022\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.9210\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.4613\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.9919\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.7183\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.3080\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.1153\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 15.9631\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 15.6904\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.5948\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.4732\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.3180\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.9870\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.8526\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.7227\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 15.7797\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.5725\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.4677\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.0407\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.5406\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.3579\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.5289\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.8174\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.3747\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 18.6774\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 17.8791\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 17.5380\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 17.4067\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 17.2442\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.8247\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.0605\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.4919\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.7891\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.7145\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.4554\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.9156\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.3381\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.3661\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.1903\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.8532\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.6025\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.3885\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 14.2357\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.2157\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.1876\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.7584\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.5599\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.6106\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 13.2930\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.3197\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.2727\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.1427\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.9122\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.6215\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.5550\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.5232\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.2528\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.2216\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.1195\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.0967\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.8709\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.6072\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.6455\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.3614\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8094\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.5052\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.1609\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.0678\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8592\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.0123\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.2043\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.3384\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.6621\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2665\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.1250\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7790\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.5312\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 10.2354\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.1370\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8986\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9389\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7262\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8099\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8845\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7056\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.4209\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.4964\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7571\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7776\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8461\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7719\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.4198\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2910\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1397\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8800\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9800\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9389\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8720\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.7825\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7333\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7928\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8450\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7113\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9040\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7581\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3296\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0075\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9081\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0353\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0106\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8713\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0627\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3234\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9305\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9910\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8339\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7304\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8657\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5380\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6058\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.4412\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3104\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3296\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5902\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5373\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.5042\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3245\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1734\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1762\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8087\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0248\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5447\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2198\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5536\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5587\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.4102\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.4118\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.2658\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2402\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2591\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1764\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0339\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9587\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0655\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0013\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8991\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0741\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9658\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1411\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0314\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0908\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5817\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2607\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2655\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0854\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9607\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0489\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1480\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6771\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5082\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.0812\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.7164\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0693\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0791\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2913\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1630\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9672\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7427\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6183\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3508\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4039\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5040\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4717\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2913\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3945\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4288\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3283\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2562\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2097\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.1349\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2504\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.1066\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3014\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.1136\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0386\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9333\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.1604\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0915\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8079\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4098\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9972\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0809\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8713\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9995\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0493\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8075\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.9682\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.7865\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8615\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.7030\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8259\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_6 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 7ms/step - loss: 46.3559\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 45.9737\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 40.3299\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 32.1883\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 27.0646\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.0178\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.1648\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.0467\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.0941\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.8185\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.6114\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.5857\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.5839\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.6615\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.5932\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.2310\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.1359\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.9944\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.0507\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.7976\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.9312\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.9150\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.8122\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.7086\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.6125\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.6336\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.4299\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 21.2022\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.3452\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.9496\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.1785\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.5562\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.5086\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.8851\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.4755\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.1784\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.9881\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.6489\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.7281\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 18.4137\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.7266\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.2992\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.8351\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.2437\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.2452\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.7267\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.1778\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.6473\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.2669\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.2886\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_7 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 3s 8ms/step - loss: 47.6535\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 47.1406\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 42.4648\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 32.5789\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 27.3694\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 25.2907\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 24.2726\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.9094\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 23.7209\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.1839\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.7000\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 24.9136\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.0006\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.8839\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.9929\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.0977\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.7543\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.2077\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.1242\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.9531\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.0464\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.6225\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.5797\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 20.4216\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.2753\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.2879\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.3232\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.2470\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.4559\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.6767\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.7754\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.6002\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.5788\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.2226\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.0200\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.8238\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.5148\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.5426\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.2391\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.7217\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.6750\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.3899\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.8087\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.5800\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.2842\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.8155\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.6891\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.1859\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.1511\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.9941\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.1524\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.9375\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.3784\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.2789\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.0365\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.9585\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.0814\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.7043\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.2709\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.1714\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.1194\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.9070\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.9155\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.7468\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.7048\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.5520\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.4775\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.5540\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.4367\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.1185\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.1329\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.0273\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.9524\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.9248\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.9859\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 13.9883\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.6649\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.6090\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.7322\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.6458\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.4110\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 13.3931\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.4832\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.3095\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.0720\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.2281\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.2082\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.0062\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.8735\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.7985\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.9090\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.5475\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.5090\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.4865\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.1356\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.1636\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.2895\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.0177\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.0111\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.3036\n",
      "26/26 [==============================] - 0s 6ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 13.3209\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.2004\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.6822\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 14.6814\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.8531\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.7154\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.2195\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.0150\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.8933\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.8246\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.6517\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.7370\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.5947\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.4922\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.4231\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.3968\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.3095\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.3209\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.2598\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.3170\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.2036\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.2380\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.1030\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.2585\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.8297\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.8897\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.8797\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.8444\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.6496\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.0493\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.4622\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.8026\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.4808\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.3596\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.0031\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.4200\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.8110\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 12.3778\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.1832\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.1492\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.9415\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.8101\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.5216\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.1740\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9346\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.3390\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.7928\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.6469\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.5390\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.2550\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_8 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 7ms/step - loss: 47.1738\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 45.0781\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 36.9297\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 28.5805\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 26.3097\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 25.6195\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 25.0371\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 25.0030\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.8620\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.9583\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.4649\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.3695\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.1939\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.0262\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 24.0555\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.9916\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 24.0500\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 23.4334\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 22.8684\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 22.5865\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.0129\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 23.0194\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 22.3212\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.2827\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.9024\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 20.4948\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 21.1633\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.9725\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.8454\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.5533\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.2590\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 19.0338\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.5815\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.1921\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.6642\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.1300\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.1257\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.7119\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 18.2578\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 17.0179\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.8739\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 16.6040\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.9585\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.6133\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.8367\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.6100\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.2624\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.8532\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.3067\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.3133\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.9725\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 14.8332\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 15.0088\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 14.7537\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 14.6008\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.3781\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.3314\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.1826\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.1598\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.5412\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.9974\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.0338\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.7866\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.7498\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.3992\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.1780\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.1608\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.0263\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.1623\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.2584\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.0693\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.1775\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.8152\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.2029\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.6835\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.4189\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.3289\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.0700\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.9488\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.9009\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.4925\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.6004\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.4382\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.2816\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.1947\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.1173\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.3039\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.7684\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.5717\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.1816\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.0170\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.9652\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.3168\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8086\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8502\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.5813\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.5198\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8152\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.9160\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.1052\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.7790\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.6112\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.1171\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.2380\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8403\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.5783\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.4721\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.3866\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2497\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.4311\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.1207\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2562\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2294\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.0106\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8780\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8815\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9137\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7520\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6930\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6960\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6328\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6418\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6528\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6496\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 9.5239\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.6323\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6195\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5892\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.4601\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5574\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.4699\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.4476\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5360\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3821\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3873\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3644\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.3584\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.0591\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.4518\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2496\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7044\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5169\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3911\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3460\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3830\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1991\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9265\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6157\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.4549\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3842\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7457\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.9439\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.4727\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.3596\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.5897\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.3826\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.4050\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.3376\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2130\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2027\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 10.1839\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.1186\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2092\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.1362\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.0500\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 15.9235\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 14.3710\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.9371\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.6965\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.1475\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.4964\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.3017\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.9195\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.7231\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.5088\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.2947\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.2429\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.2139\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.0731\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.0233\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.9543\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.9581\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8963\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8848\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8705\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.9034\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7792\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7201\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7430\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7334\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7049\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.6401\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7685\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.5744\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7331\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 10.7824\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.7670\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.6107\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.6440\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.3698\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 11.3228\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 10.4885\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.8452\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.7041\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3908\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.2810\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1552\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1931\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1245\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1548\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0329\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.9299\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9380\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7705\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8280\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8022\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8204\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7375\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7111\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6470\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5998\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6004\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7281\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.0164\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8216\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7871\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1897\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0850\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8550\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9208\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6893\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6569\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6653\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0322\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.0352\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.1802\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.8780\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.7389\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7893\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.6831\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5946\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5054\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5670\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.4846\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.4524\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.5148\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8819\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.8580\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0724\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7581\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_9 (Masking)         (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 7ms/step - loss: 13.8705\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.5084\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.3878\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.2019\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 12.7158\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 12.6652\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.8076\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.2626\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.1292\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.1043\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9881\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.5488\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.6700\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.3536\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.3063\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0625\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3094\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0893\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0654\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.0205\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.8347\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8013\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7676\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3993\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8629\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5469\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3795\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.1235\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3952\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0386\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8698\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8087\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7889\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.4172\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0240\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9615\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0776\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8991\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9720\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.4250\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.6315\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9170\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.7447\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2756\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0637\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0545\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9517\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.4672\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.2119\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.0735\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_10 (Masking)        (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 3s 8ms/step - loss: 13.9144\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.5054\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.4087\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.2771\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9934\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.3988\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.5536\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.9343\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.4239\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.2637\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.8308\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.9022\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.3467\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.3777\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.0764\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.7833\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.9833\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.8511\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.7301\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.6021\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2403\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 8.1296\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.0103\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.8978\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7443\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.9758\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.6561\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.9887\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7721\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.4807\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.2781\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3813\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.1290\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0827\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7655\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.5935\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.5404\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4752\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4982\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.5021\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4001\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4382\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3686\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4186\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3330\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3859\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0873\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0580\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.5571\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3256\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.9808\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.7450\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.4974\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.6657\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.2509\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.1011\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.0330\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.7772\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.8447\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.5268\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.6584\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.6063\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4214\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4242\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3010\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3840\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.3124\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4500\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3847\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2592\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2448\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2689\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2840\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2400\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0173\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0227\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.9203\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.8606\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.8109\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.7393\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.6546\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.5746\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.5703\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.5937\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.5587\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.4687\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4461\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0849\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.3152\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.7724\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.6106\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.3827\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.4377\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.1875\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3500\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2431\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2168\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.6290\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.9140\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.6988\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.2299\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.9074\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.6239\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.6596\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.3942\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3735\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2877\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2999\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.3106\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2305\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.1218\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.9832\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0933\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.0265\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9306\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.8854\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.8283\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.9710\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.5961\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.9127\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.6827\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.9717\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.9299\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.5014\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 5.9236\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.5604\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.2567\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.1918\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.0898\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.2855\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.3544\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8763\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.8566\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.5994\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.5435\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4437\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3747\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3262\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.2312\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.9622\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.9491\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.9167\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.8261\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 4.8382\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.8293\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.8076\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.7825\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.8322\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.7345\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 4.7242\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_11 (Masking)        (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 7ms/step - loss: 14.1032\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.8146\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.7141\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.5890\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 13.3843\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.7501\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 12.0614\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 12.4620\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 11.7829\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.2816\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1298\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3056\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.1890\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8868\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7377\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.9759\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0298\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3507\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0719\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.0414\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 9.2547\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1843\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2147\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.3943\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.9156\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8276\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1747\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.1185\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.8736\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.7698\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.4387\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2841\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.0887\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.8788\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6765\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.4303\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2360\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2362\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.1973\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.5248\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.3395\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.6798\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.4685\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0268\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.7966\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9273\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8124\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.3723\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.3708\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.3883\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 8.0331\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.6525\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.2030\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9130\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8893\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9357\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8417\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.6639\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.6389\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.0822\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.1908\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9518\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.9421\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8451\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.8920\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.6184\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.5012\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.4175\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.4148\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.2940\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.3270\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.2648\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.1934\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.1575\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.0966\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.0499\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.3297\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.9926\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.5129\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.9472\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.8421\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 10.7118\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 9.3778\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.4881\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 8.2847\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9106\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.9213\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 7.6923\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 7.5238\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.8545\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.5521\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.5521\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.3788\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.7089\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.6216\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.1433\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.1092\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.8957\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.7152\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.7946\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.7246\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 5.7208\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.5948\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 5.6322\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.0987\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.7241\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.5687\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.8125\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.5566\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4888\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4434\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4378\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.3621\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.3419\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2887\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2606\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2579\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2109\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1693\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2528\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1871\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1815\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1438\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 5.0821\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 6.0701\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 5.7882\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4722\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.3288\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2698\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2914\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0843\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1766\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0497\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1175\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0879\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1157\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.8946\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.8693\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.8589\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.7843\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7560\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9031\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.2832\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.8434\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7533\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7213\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6501\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6064\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6053\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5959\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1092\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0675\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9738\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.8719\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7827\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6972\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7641\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7131\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5963\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6303\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.6644\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.6692\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.5797\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.0779\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.7954\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.8834\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9501\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6843\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4753\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4249\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3249\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.8138\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5279\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4733\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.4928\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5166\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3584\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.8302\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.1343\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.7968\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4323\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4046\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3886\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3406\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2462\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2360\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2428\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2052\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1623\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2165\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1817\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1202\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0921\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1106\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0596\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1442\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.1825\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.1061\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.1324\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.1595\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4590\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.4968\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.5523\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3750\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3908\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3457\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3004\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3954\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3162\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 4.6849\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 5.4079\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 6.0750\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.9275\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.6233\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3846\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3468\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.3225\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1946\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2268\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1918\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.2185\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1243\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0799\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1326\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0911\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0665\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1008\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0776\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0802\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0889\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0429\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0087\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0041\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9873\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 3.9618\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 3.9827\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 3.9285\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1074\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0770\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0289\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9761\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9538\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9242\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9112\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 3.9623\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9116\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.0737\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 4.1257\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 3.9816\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 3.9677\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "[8.731634542205798]\n",
      "[8.449291420341993, 9.383950875746727, 9.39688702358522]\n",
      "[8.069236453649216, 7.784921785039566, 9.47486384938621, 8.599084617853153, 9.674130969033204]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use results from this cell for the final paper******************************************************************************\n",
    "\n",
    "for y in Y:\n",
    "    sequential_split = test_models(sequential_model, X, y)\n",
    "    sequential_kf3 = train_models(sequential_model, X, y, kfold=3)\n",
    "    sequential_kf5 = train_models(sequential_model, X, y, kfold=5)\n",
    "\n",
    "for i in [sequential_split, sequential_kf3, sequential_kf5]:\n",
    "    print(i[1])\n",
    "plot_model(sequential_split[0], show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9480f33f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:09:53.367984Z",
     "iopub.status.busy": "2023-05-07T03:09:53.367223Z",
     "iopub.status.idle": "2023-05-07T03:19:25.089355Z",
     "shell.execute_reply": "2023-05-07T03:19:25.088221Z"
    },
    "papermill": {
     "duration": 574.039664,
     "end_time": "2023-05-07T03:19:25.091981",
     "exception": false,
     "start_time": "2023-05-07T03:09:51.052317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_12 (Masking)        (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 4s 9ms/step - loss: 33.6074\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.8033\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.6762\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.5383\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.3363\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.9442\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.4572\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.6911\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.8926\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.4853\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 15.7792\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 15.3318\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.9293\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.2767\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.8331\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.5854\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.2449\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.9236\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.5776\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.2470\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.9941\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.5905\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.3378\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.6310\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.1078\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.0130\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.8891\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.6720\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.6824\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.4413\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.3916\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.2564\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 10.2051\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.9782\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.1532\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.8793\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.7433\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.6790\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.5476\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.5947\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.4544\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.3213\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.3104\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.3066\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.2009\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.1880\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.0427\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.0707\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.9236\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.9571\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.2442\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 11.6320\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.1866\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.9406\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.5433\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.4599\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.3336\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.1495\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 10.0446\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.9033\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.8394\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.7071\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.7220\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.6503\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.4875\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.3854\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.2492\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.2909\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.1474\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.0880\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.9518\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.8304\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.8632\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.7000\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.5503\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.6339\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.6805\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 8.5958\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 8.4567\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.4021\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.4186\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.2806\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2269\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.0823\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.1159\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.0726\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.1110\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.1207\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.0622\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.9100\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.9467\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.8711\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.7303\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.7001\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.6839\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.7077\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.6123\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.6219\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.5347\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.5296\n",
      "26/26 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.8411\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.3748\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 9.2357\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.9788\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.7862\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.6680\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.5048\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.2766\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.1780\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.2057\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.2486\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 8.1340\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.0351\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.9753\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.8972\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.6970\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.5952\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.4734\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.5831\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.4061\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.2766\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.2499\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.1056\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.1526\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.9233\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.0375\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.9587\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0889\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.8403\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.8687\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.8302\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.6859\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.6795\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.6668\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.6103\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4954\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.5072\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4555\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 6.6112\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4176\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4077\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2391\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2249\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2935\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2377\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 6.1290\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0918\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0610\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0309\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.0240\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_13 (Masking)        (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 5s 9ms/step - loss: 43.8106\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 39.9931\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 27.8106\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 26.9922\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 31.1214\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 28.8774\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.7549\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.9804\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.2885\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.6626\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.0920\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.9407\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.7129\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.2127\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 27.9627\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 27.9239\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 27.7626\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 27.1062\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 25.6556\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.6920\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.4835\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.7906\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.7700\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.8182\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 21.0915\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.4177\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.6536\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.0479\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.1458\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.8685\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.3418\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.2403\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.9714\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.4194\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.2673\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.2662\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.7922\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.0780\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.0540\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.3943\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.3036\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.4670\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.9807\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.4140\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.5183\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.1304\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.7664\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.9740\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.3645\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.0783\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.4883\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.1226\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 17.2907\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 18.8504\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.7128\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.5764\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 16.7544\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.5862\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.3173\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.3265\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.2451\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.4012\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.9951\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.8163\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.6303\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.6943\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.8841\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.4205\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.1968\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.1800\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 15.0629\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.8375\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.1768\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.8029\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.3891\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5610\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.6073\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.6608\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.8397\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5548\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.3755\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.6470\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.5067\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.0456\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.8189\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.3113\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.0002\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.7688\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.5697\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 11ms/step - loss: 12.3997\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 12.3271\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.3018\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.1581\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.1521\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 12.0736\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.1591\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.1455\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.2256\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.0795\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.9004\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.3298\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.6422\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.7639\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.8570\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.4512\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.4862\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.3745\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.3435\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.1565\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.1565\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.7089\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.6752\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.6970\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.9060\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.6975\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.5809\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.6832\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.8408\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.0652\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.3511\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.0233\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.0447\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.1532\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 12ms/step - loss: 12.1654\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 11.6224\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.4857\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.4813\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.2489\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.4835\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.2581\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.1232\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.9857\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.7901\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 10.7358\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.8536\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.7434\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.7301\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.6358\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.4984\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.2325\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.4191\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.5900\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.4089\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.4764\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.7259\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.9459\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 11.7661\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.7585\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.8293\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.1714\n",
      "26/26 [==============================] - 0s 5ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_14 (Masking)        (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 4s 9ms/step - loss: 47.4822\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 47.0002\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 43.9958\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 31.9084\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 26.3606\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 24.8175\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 24.5879\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.6127\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.0948\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.9643\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.1720\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.5679\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.9117\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.6779\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.3242\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.4875\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.7457\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.4560\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 24.4380\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 24.8375\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.5172\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.2585\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.5095\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.2803\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.0137\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.1156\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.2433\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.9050\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 23.0781\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 22.5845\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 23.0428\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.4962\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 22.3937\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.8540\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.7756\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.7794\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.5543\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.5065\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.7532\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.9262\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.7107\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.7535\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 21.8817\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.4692\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 19.8654\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.5541\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.2406\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.1416\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.8440\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.5278\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.8436\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.8082\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 20.0805\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.6217\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.0966\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.9762\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.0372\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 18.7381\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 19.7325\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.9169\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.0119\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.9532\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.5319\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.2591\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.3621\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.0182\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.4533\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 18.1980\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.9771\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.7765\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.6004\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.4110\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.2867\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.0684\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.8600\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.9735\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.8832\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.6505\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.5229\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.4811\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.7000\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.3232\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 16.1595\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.8734\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.8854\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.9693\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5110\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.4307\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5219\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.8900\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.9114\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5858\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.2486\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.2336\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.9142\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8654\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.7221\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.6547\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.6037\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.5219\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.6861\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.4640\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.3756\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.1616\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.3433\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 15.1206\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.8002\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.8500\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.4537\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.4542\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.9774\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 19.7151\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 17.6765\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 17.1770\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.6550\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.6265\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.5397\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.9742\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.8149\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.7696\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.2625\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.5136\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.6207\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.1100\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.9702\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 14.7163\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.5304\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.9647\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.9474\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.6219\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.4803\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.3231\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.2600\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.1945\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.1413\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.1549\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.1321\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.0485\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.1156\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.0952\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.1634\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 16.4904\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.8163\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.6155\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 15.2348\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.8255\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.3652\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 14.1227\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.9449\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.8428\n",
      "26/26 [==============================] - 0s 5ms/step\n",
      "<function SMAPE at 0x78a9045465f0>\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_15 (Masking)        (None, 10, 227)           0         \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 10, 16)            7280      \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 64)                20736     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,276\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 4s 9ms/step - loss: 14.1455\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.8014\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.6590\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 13.4776\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 13.0650\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 12.1622\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 11.7983\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.6790\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.9396\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.7479\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.7069\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.3764\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.5627\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.2682\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.8383\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 9.0038\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 9.1441\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.5341\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.2445\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.3618\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.0514\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.9341\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.8926\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.7254\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.7184\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.7715\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.6432\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.5722\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.3855\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.7051\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.5396\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.4608\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.2829\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.1178\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.2648\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.1496\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.2574\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 8.7451\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7472\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.9878\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.8721\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.7246\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4954\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4731\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.3939\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4793\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4691\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2689\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2177\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1509\n",
      "26/26 [==============================] - 1s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.6728\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 7.7482\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.4421\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.4876\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.8892\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.5687\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.2724\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.4793\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.1652\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.2467\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.7121\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0889\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.8969\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.8739\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.7068\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7455\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.6230\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.6684\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.4812\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 10.6756\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.8205\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 8.1113\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.3525\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0258\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.8383\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.1469\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.8837\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.7726\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7550\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0240\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.0344\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.8760\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.8843\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.4500\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 7.2192\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.8854\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.7896\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.6234\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.5897\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.5114\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4950\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.6206\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.6070\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.4947\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3652\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.2155\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1589\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.1554\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.0771\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.0068\n",
      "26/26 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.6206\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.7222\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4064\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 7.1759\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.3988\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.7883\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.4499\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.3644\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.2865\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 6.0076\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 6.1904\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.8415\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.8702\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.7676\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.7407\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.7032\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.6272\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.7045\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.6078\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.6225\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 5.6089\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.5512\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.5539\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.5948\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.5275\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.4421\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4634\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3854\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4179\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3981\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.4016\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.3618\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3427\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4253\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3023\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4390\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3707\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.3723\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3110\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4001\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.4108\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.3338\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.3014\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.2436\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.2835\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.2172\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.2383\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 5.1644\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.1309\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 5.1083\n",
      "26/26 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "trained_model, scores = zip(*[train_models(sequential_model, X, y, kfold=3) for y in Y])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63838a24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:19:31.102012Z",
     "iopub.status.busy": "2023-05-07T03:19:31.101141Z",
     "iopub.status.idle": "2023-05-07T03:19:31.106626Z",
     "shell.execute_reply": "2023-05-07T03:19:31.105631Z"
    },
    "papermill": {
     "duration": 3.073854,
     "end_time": "2023-05-07T03:19:31.109062",
     "exception": false,
     "start_time": "2023-05-07T03:19:28.035208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <keras.engine.sequential.Sequential object at 0x78a8fa153910>\n",
      "scores: [5.095059863439958, 5.058729776920125, 5.219820241468249]\n",
      "\n",
      "model: <keras.engine.sequential.Sequential object at 0x78a8f91c5d50>\n",
      "scores: [6.744517983409071, 7.630473940202817, 6.7591920352707335]\n",
      "\n",
      "model: <keras.engine.sequential.Sequential object at 0x78a903c4db10>\n",
      "scores: [3.9738598551273423, 4.739246440918109, 3.49064066465267]\n",
      "\n",
      "model: <keras.engine.sequential.Sequential object at 0x78a903a688b0>\n",
      "scores: [9.042829675876122, 9.076049606867509, 9.904487184373906]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(f'model: {trained_model[i]}\\nscores: {scores[i]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c0d9b7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:19:37.121798Z",
     "iopub.status.busy": "2023-05-07T03:19:37.121392Z",
     "iopub.status.idle": "2023-05-07T03:19:37.131419Z",
     "shell.execute_reply": "2023-05-07T03:19:37.130148Z"
    },
    "papermill": {
     "duration": 2.979353,
     "end_time": "2023-05-07T03:19:37.133679",
     "exception": false,
     "start_time": "2023-05-07T03:19:34.154326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_submission_df(predictions, ids, loop):\n",
    "    updrs_list = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']\n",
    "    months = [0,6,12,18,24,36,48,60,72,84]\n",
    "    month = months[loop]\n",
    "    plus_list = [0,6,12,24]\n",
    "    \n",
    "    prediction_ids = []\n",
    "    \n",
    "    all_predictions = round_min_zero(predictions)\n",
    "    for i,preds in enumerate(all_predictions):\n",
    "        patient = 0\n",
    "        prediction_ids.append([])\n",
    "        preds = preds.reshape(4*len(preds))\n",
    "        for j,pred in enumerate(preds):\n",
    "            plus_month = plus_list[j%4]\n",
    "            prediction_ids[-1].append('_'.join([str(ids[patient]),str(month),updrs_list[i], 'plus', str(plus_month), 'months']))\n",
    "            patient += (j%4+1)//4\n",
    "    \n",
    "    dfs = []\n",
    "    for pred_ids, pred in zip(prediction_ids, all_predictions):\n",
    "        pred = pred.reshape(4*len(pred))\n",
    "        pred_ids = np.array(pred_ids)\n",
    "        dfs.append(pd.DataFrame({'prediction_id':pred_ids, 'rating':pred}).set_index('prediction_id'))\n",
    "\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68fdc77d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:19:42.994345Z",
     "iopub.status.busy": "2023-05-07T03:19:42.993620Z",
     "iopub.status.idle": "2023-05-07T03:19:43.022756Z",
     "shell.execute_reply": "2023-05-07T03:19:43.021626Z"
    },
    "papermill": {
     "duration": 2.964183,
     "end_time": "2023-05-07T03:19:43.025312",
     "exception": false,
     "start_time": "2023-05-07T03:19:40.061129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import amp_pd_peptide_310\n",
    "env = amp_pd_peptide_310.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42c59744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:19:49.019060Z",
     "iopub.status.busy": "2023-05-07T03:19:49.018453Z",
     "iopub.status.idle": "2023-05-07T03:19:49.759418Z",
     "shell.execute_reply": "2023-05-07T03:19:49.757776Z"
    },
    "papermill": {
     "duration": 3.702687,
     "end_time": "2023-05-07T03:19:49.761413",
     "exception": true,
     "start_time": "2023-05-07T03:19:46.058726",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'method' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (test, test_peptides, test_proteins, sample_submission) \u001b[38;5;129;01min\u001b[39;00m iter_test:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_proteins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([data, pd\u001b[38;5;241m.\u001b[39mread_csv(test_proteins)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:704\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    701\u001b[0m errors \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;00m\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_binary_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    705\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# validate encoding and errors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:1163\u001b[0m, in \u001b[0;36m_is_binary_mode\u001b[0;34m(handle, mode)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(handle), text_classes):\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, _get_binary_io_classes()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'method' is not iterable"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "loop = 0\n",
    "for (test, test_peptides, test_proteins, sample_submission) in iter_test:\n",
    "    if loop == 0:\n",
    "        data = pd.read_csv(test_proteins)\n",
    "    else:\n",
    "        data = pd.concat([data, pd.read_csv(test_proteins)], axis=0)\n",
    "    test_input, test_patients, correct_month = test_data_prep(data, train_uniprot_ids, scaler_object)\n",
    "    print(correct_month)\n",
    "    \n",
    "    # Double and Triple check that data is fully imputed aka no nan values\n",
    "    if test_input.isna().sum().sum() > 0:\n",
    "        test_input.fillna(data.mean(), inplace=True)\n",
    "        print('column mean imputation required')\n",
    "    if test_input.isna().sum().sum() > 0:\n",
    "        test_input.fillna(0, inplace=True)\n",
    "        print('zero imputation required')\n",
    "        print(test_input.head(10))\n",
    "    print(test_input.shape)\n",
    "    \n",
    "    temp_results = [model.predict(test_input) for model in trained_model]\n",
    "    \n",
    "    \n",
    "    sample_submission = create_submission_df(temp_results, test_patients, loop)\n",
    "    \n",
    "    \n",
    "    # final line, outputs csv for submission. Need to pass in a dataframe.\n",
    "    # columns are prediction_id and rating\n",
    "    env.predict(sample_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2660.207449,
   "end_time": "2023-05-07T03:19:56.245732",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-07T02:35:36.038283",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
