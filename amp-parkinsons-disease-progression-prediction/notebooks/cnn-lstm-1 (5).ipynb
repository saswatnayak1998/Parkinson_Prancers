{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Sequential, Model\nfrom tensorflow.keras import backend as kb\nfrom keras.utils.vis_utils import plot_model\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import StandardScaler\nimport sys\nsys.path.append('/kaggle/input/amp-pd')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T04:54:39.341888Z","iopub.execute_input":"2023-05-08T04:54:39.343697Z","iopub.status.idle":"2023-05-08T04:54:48.955925Z","shell.execute_reply.started":"2023-05-08T04:54:39.343656Z","shell.execute_reply":"2023-05-08T04:54:48.954862Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\ndf_train_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\ndf_train_clinical = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T04:54:48.957556Z","iopub.execute_input":"2023-05-08T04:54:48.958188Z","iopub.status.idle":"2023-05-08T04:54:50.792891Z","shell.execute_reply.started":"2023-05-08T04:54:48.958155Z","shell.execute_reply":"2023-05-08T04:54:50.791942Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def get_lin_reg(mat):\n    if mat.shape[0] == 1:\n        return 0, mat[0,1]\n    \n    X = mat[:,0]\n    X = np.vstack([X, np.ones(len(X))]).T\n    Y = mat[:,1]\n    \n    # res = np.dot(np.linalg.inv(X.T@X)@X.T, Y)            # This might be faster? (Uses pseudoinverse to calculate weights)\n    res = np.around(np.linalg.lstsq(X,Y, rcond=None)[0])\n    return res\n\n\ndef lin_reg_imputation(df, complete=False, style='mean'):\n    global t0\n    # res = [0]*len(df.patient_id.unique())       # To preallocate a list, might be faster?\n    # i = 0                                       # If using preallocation\n    res= []\n    for patient, group in df.groupby('patient_id'):\n        months = group['visit_month']\n        for col in group:\n            data = group[col]\n            if data.isna().sum() not in (0, len(data)):\n                m,b = get_lin_reg(pd.concat([months,data], axis=1).dropna().values)\n                group[col].fillna(m*months + b, inplace=True)\n        res.append(group)\n        # res[i] = group                          # If using preallocation\n        # i += 1                                  # If using preallocation\n    df_linreg = pd.concat(res)\n    if complete:\n        if style=='mean':\n            df_linreg.fillna(df_linreg.mean(), inplace=True)\n        elif style=='zero':\n            df_linreg.fillna(0, inplace=True)\n        else:\n            raise Exception(f'\"{style}\" is not a valid imputation method. Available options are \"mean\" or \"zero\"')\n    return df_linreg\n\n\ndef test_data_prep(proteins, uniprot_ids, scaler, shown, concat=True):\n    \n    # Remove extra proteins\n    new_uniprots = set(proteins.UniProt.unique())\n    extra_prots = new_uniprots.difference(uniprot_ids)\n    proteins = proteins.drop(extra_prots)\n    print('removed extras')\n    print(f'removed {extra_prots}')\n    \n    # Reshape\n    protein_pivot = df_train_proteins.pivot(index='visit_id', columns='UniProt', values='NPX')\n    protein_pivot = protein_pivot.reset_index()\n    \n    p_id, v_id = zip(*(v_id.split('_') for v_id in protein_pivot.visit_id.values))\n    proteins = protein_pivot\n    proteins.insert(1, 'patient_id', np.array(p_id).astype('int32'))\n    proteins.insert(2, 'visit_month', np.array(v_id).astype('int32'))\n    print('pivoted and merged')\n    \n    # Impute missing values\n    if proteins.isna().sum().sum() > 0:\n        protein_lr = lin_reg_imputation(proteins, complete=True)\n        print('imputed')\n        print(protein_lr.isna().sum().sum())\n    else:\n        protein_lr = proteins\n    \n    # Scale protein NPX values\n    columns = protein_lr.columns\n    sc = scaler\n    protein_lr = pd.DataFrame(sc.transform(protein_lr.iloc[:,3:]), columns=columns[3:])\n    protein_lr = pd.concat([proteins.iloc[:,:3], protein_lr], axis=1)\n    print('scaled')\n    \n    # Reshape for LSTM\n    months = [0,6,12,18,24,36,48,60,72,84]\n    num_proteins=len(uniprot_ids)\n    shown = months[:shown+1]\n    X_iter = []\n    sample_info = []\n    for patient_id, group in protein_lr.groupby('patient_id'):\n        X_iter.append([])\n        sample_info.append(patient_id)\n        verify_month = shown[-1] in group.visit_month.values\n        for month in months:\n            if month in shown and month in group.visit_month.values.astype('int'):\n                X_iter[-1].append(*group[group.visit_month==month].iloc[:,3:].values)\n            else:\n                X_iter[-1].append(np.full(num_proteins,-1))\n    X = np.array(X_iter)\n    print('reshaped')\n    \n    if concat:\n        X = np.concatenate(X, axis=0)\n        print('concatenated')\n        \n    return X, sample_info, verify_month\n\n\ndef train_data_prep(clinical, proteins, concat=True):\n    \n    # Modify protein shape\n    protein_pivot = df_train_proteins.pivot(index='visit_id', columns='UniProt', values='NPX')\n    protein_pivot = protein_pivot.reset_index()\n    print('pivoted')\n    \n    # Merge with UPDRS scores and remove medication state column\n    updrs_protein = pd.merge(clinical.drop(['upd23b_clinical_state_on_medication'], axis=1), \n                             protein_pivot, \n                             on=['visit_id'])\n    print('merged')\n    \n    # Impute missing values\n    protein_data = updrs_protein.drop(['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)\n    protein_lr = lin_reg_imputation(protein_data, complete=True)\n    print('imputed')\n    \n    # Scale protein NPX values\n    columns = protein_lr.columns\n    sc = StandardScaler()\n    protein_lr = pd.DataFrame(sc.fit_transform(protein_lr.iloc[:,3:]), columns=columns[3:])\n    protein_lr = pd.concat([updrs_protein.iloc[:,:7], protein_lr], axis=1)\n    print('scaled')\n    \n    # Remove useless rows from train data\n    updrs_subset = protein_lr.iloc[:,:7]\n    for month in (3,30,54,96,108):\n        protein_lr.drop(protein_lr[protein_lr.visit_month == month].index, inplace=True)\n    print('removed rows from protein_lr')\n    \n    # Reshape X and Y data for LSTM\n    X_iter = []\n    months = [0,6,12,18,24,36,48,60,72,84]\n    num_proteins=227\n    for i in range(len(months)):\n        shown = months[:i+1]\n        X_iter.append([])\n        for patien_id, group in protein_lr.groupby('patient_id'):\n            X_iter[-1].append([])\n            for month in months:\n                if month in shown and month in group.visit_month.values:\n                    X_iter[-1][-1].append(*group[group.visit_month==month].iloc[:,7:].values)\n                else:\n                    X_iter[-1][-1].append(np.full(227,-1))\n\n    Y_iter = []\n    for i,month in enumerate(months):\n        shown = months[:i+1]\n        Y_iter.append([])\n        for patient_id, group in updrs_subset.groupby('patient_id'):\n            Y_iter[-1].append([])\n            for month2 in [month, month+6, month+12, month+24]:\n                if month2 in group.visit_month.values:\n                    if group.isna().sum().sum() >0:\n                        group.fillna(value=-1, inplace=True)\n                    Y_iter[-1][-1].append(*group[group.visit_month==month2].iloc[:,3:].values)\n\n                else:\n                    Y_iter[-1][-1].append(np.full(4,-1))\n\n    X = np.array(X_iter)\n    Y = np.array(Y_iter)\n    print(f'Reshaped\\nX:{X.shape}\\nY:{Y.shape}')\n    \n    # Split Y into 4, one for each UPDRS\n    Y1, Y2, Y3, Y4 = np.split(Y, [1,2,3], axis=3)\n    for i,data in enumerate([Y1, Y2, Y3, Y4]):\n        print(f'UPDRS {i+1} shape: {data.shape}')\n              \n    if concat:\n        X = np.concatenate(X, axis=0)\n        Y1 = np.concatenate(Y1, axis=0)\n        Y2 = np.concatenate(Y2, axis=0)\n        Y3 = np.concatenate(Y3, axis=0)\n        Y4 = np.concatenate(Y4, axis=0)\n    \n    return X, [Y1, Y2, Y3, Y4], sc\n    \n\ndef SMAPE(y_true, y_pred):\n    \"\"\"\n    Computes the Symmetric Mean Absolute Percentage Error (SMAPE) loss between y_true and y_pred.\n    \"\"\"\n    mask = y_true!=-1\n    y_pred = y_pred*kb.cast(mask,tf.float32)\n    y_true = y_true*kb.cast(mask,tf.float32)\n    \n    # Comment out later\n    # y_pred = y_pred+1\n    # y_true = y_true+1\n\n    epsilon = 0.1\n    summ = kb.maximum(kb.abs(y_true) + kb.abs(y_pred) + epsilon, 0.5+epsilon)\n    # summ = kb.abs(y_true) + kb.abs(y_pred)\n    smape = kb.mean(kb.abs(y_pred - y_true) / summ * 2)\n    return smape*100\n\n\ndef round_min_zero(nums):\n    nums = np.around(nums).astype(int)\n    return np.maximum(0,nums)\n\n\ndef check_smape(y_pred, y_true):\n    y_pred = round_min_zero(y_pred)\n    \n    y_true = y_true.reshape(y_pred.shape)\n    mask = y_true!=-1\n    y_pred = y_pred*mask +1\n    y_true = y_pred*mask +1\n    \n    summ = np.abs(y_pred) + np.abs(y_true)\n    smape = np.mean(np.abs(y_pred-y_true) / summ *2)\n    return smape*100\n\n\ndef sequential_model(input_shape, concat=True):\n    print(SMAPE)\n    if concat:\n        shape = input_shape[1:]\n    else:\n        shape = input_shape[2:]\n\n    lstm_model = Sequential()\n    lstm_model.add(layers.Masking(mask_value=-1, input_shape=shape))\n    lstm_model.add(layers.Conv1D(16,2,padding='same'))\n    lstm_model.add(layers.LSTM(64))\n    lstm_model.add(layers.Dense(4))\n    lstm_model.compile(loss=SMAPE, optimizer='adam')\n    lstm_model.summary()\n    return lstm_model\n\n\n#def API_model(input_shape, concat=True):\n#    if concat:\n#        shape = input_shape[1:]\n#    else:\n#        shape = input_shape[2:]\n#    \n#    inputs = layers.Input(shape)\n#    mask = layers.Masking(mask_value=-1).compute_mask(inputs)\n#    conv = layers.Conv1D(16,2,padding='same')(inputs)\n#    lstm = layers.LSTM(64)(conv, mask=mask)\n#    out = layers.Dense(4)(lstm)\n#    model = Model(inputs,out)\n#    model.compile(loss=SMAPE, optimizer='adam')\n#    model.summary()\n#    return model\n\n\ndef test_models(model_func, X_data, Y_data, eps=50, batch=16, kfold=None, test_size=0.2, concat=True):\n    scores = []\n    X_ftrain, X_ftest, Y_ftrain, Y_ftest = train_test_split(X_data, Y_data, shuffle=True, test_size=test_size)\n    model = model_func(X_ftrain.shape)\n    if kfold:\n        kf = KFold(n_splits=kfold, shuffle=True)\n        for train_index, test_index in kf.split(X_ftrain, Y_ftrain):\n            X_train, X_test = X_ftrain[train_index], X_ftrain[test_index]\n            Y_train, Y_test = Y_ftrain[train_index], Y_ftrain[test_index]\n            model.fit(X_train,Y_train, epochs=eps, batch_size=batch)\n            scores.append(check_smape(model.predict(X_test),Y_test))\n    else:\n        model.fit(X_ftrain,Y_ftrain, epochs=eps, batch_size=batch)\n        \n    predictions = model.predict(X_ftest)\n    scores.append(check_smape(predictions,Y_ftest))\n    return model, scores, [predictions, Y_ftest]\n\n\ndef train_models(model_func, X_data, Y_data, eps=50, batch=16, kfold=None, test_size=0.2, concat=True):\n    scores = []\n    model = model_func(X_data.shape)\n    if kfold:\n        kf = KFold(n_splits=kfold, shuffle=True)\n        for train_index, test_index in kf.split(X_data, Y_data):\n            X_train, X_test = X_data[train_index], X_data[test_index]\n            Y_train, Y_test = Y_data[train_index], Y_data[test_index]\n            model.fit(X_train,Y_train, epochs=eps, batch_size=batch)\n            scores.append(check_smape(model.predict(X_test),Y_test))\n    else:\n        model.fit(X_data,Y_data, epochs=eps, batch_size=batch)\n        scores.append(check_smape(model.predict(X_data),Y_data))\n    return model, scores","metadata":{"execution":{"iopub.status.busy":"2023-05-08T04:54:50.794507Z","iopub.execute_input":"2023-05-08T04:54:50.795214Z","iopub.status.idle":"2023-05-08T04:54:50.841151Z","shell.execute_reply.started":"2023-05-08T04:54:50.795176Z","shell.execute_reply":"2023-05-08T04:54:50.839671Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Need list of proteins in train in case extra proteins in test API\ntrain_uniprot_ids = set(df_train_proteins.UniProt.unique())","metadata":{"execution":{"iopub.status.busy":"2023-05-08T04:54:50.843831Z","iopub.execute_input":"2023-05-08T04:54:50.844150Z","iopub.status.idle":"2023-05-08T04:54:50.881426Z","shell.execute_reply.started":"2023-05-08T04:54:50.844124Z","shell.execute_reply":"2023-05-08T04:54:50.879867Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X, Y, scaler_object = train_data_prep(df_train_clinical, df_train_proteins)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T04:54:50.882810Z","iopub.execute_input":"2023-05-08T04:54:50.884233Z","iopub.status.idle":"2023-05-08T04:55:24.575490Z","shell.execute_reply.started":"2023-05-08T04:54:50.884194Z","shell.execute_reply":"2023-05-08T04:55:24.574168Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"pivoted\nmerged\nimputed\nscaled\nremoved rows from protein_lr\nReshaped\nX:(10, 248, 10, 227)\nY:(10, 248, 4, 4)\nUPDRS 1 shape: (10, 248, 4, 1)\nUPDRS 2 shape: (10, 248, 4, 1)\nUPDRS 3 shape: (10, 248, 4, 1)\nUPDRS 4 shape: (10, 248, 4, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Use results from this cell for the final paper******************************************************************************\nsequential_split = []\nsequential_kf3 = []\nsequential_kf5 = []\nfor y in Y:\n    sequential_split.append(test_models(sequential_model, X, y))\n    sequential_kf3.append(test_models(sequential_model, X, y, kfold=3))\n    sequential_kf5.append(test_models(sequential_model, X, y, kfold=5))","metadata":{"execution":{"iopub.status.busy":"2023-05-08T05:42:05.517734Z","iopub.execute_input":"2023-05-08T05:42:05.518100Z","iopub.status.idle":"2023-05-08T05:43:12.101622Z","shell.execute_reply.started":"2023-05-08T05:42:05.518072Z","shell.execute_reply":"2023-05-08T05:43:12.099757Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"<function SMAPE at 0x79a69aec2c20>\nModel: \"sequential_12\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n masking_12 (Masking)        (None, 10, 227)           0         \n                                                                 \n conv1d_12 (Conv1D)          (None, 10, 16)            7280      \n                                                                 \n lstm_12 (LSTM)              (None, 64)                20736     \n                                                                 \n dense_12 (Dense)            (None, 4)                 260       \n                                                                 \n=================================================================\nTotal params: 28,276\nTrainable params: 28,276\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n124/124 [==============================] - 3s 7ms/step - loss: 32.3708\nEpoch 2/50\n124/124 [==============================] - 1s 7ms/step - loss: 20.2152\nEpoch 3/50\n124/124 [==============================] - 1s 7ms/step - loss: 19.9147\nEpoch 4/50\n124/124 [==============================] - 1s 7ms/step - loss: 19.5095\nEpoch 5/50\n124/124 [==============================] - 1s 7ms/step - loss: 18.8677\nEpoch 6/50\n124/124 [==============================] - 1s 7ms/step - loss: 18.2704\nEpoch 7/50\n124/124 [==============================] - 1s 7ms/step - loss: 17.4232\nEpoch 8/50\n124/124 [==============================] - 1s 7ms/step - loss: 16.7713\nEpoch 9/50\n124/124 [==============================] - 1s 7ms/step - loss: 16.1418\nEpoch 10/50\n124/124 [==============================] - 1s 7ms/step - loss: 15.6890\nEpoch 11/50\n124/124 [==============================] - 1s 8ms/step - loss: 14.7005\nEpoch 12/50\n124/124 [==============================] - 1s 7ms/step - loss: 14.2582\nEpoch 13/50\n124/124 [==============================] - 1s 7ms/step - loss: 13.7897\nEpoch 14/50\n124/124 [==============================] - 1s 7ms/step - loss: 13.6554\nEpoch 15/50\n124/124 [==============================] - 1s 7ms/step - loss: 13.3252\nEpoch 16/50\n124/124 [==============================] - 1s 7ms/step - loss: 12.7056\nEpoch 17/50\n124/124 [==============================] - 1s 7ms/step - loss: 12.5689\nEpoch 18/50\n124/124 [==============================] - 1s 7ms/step - loss: 12.3489\nEpoch 19/50\n124/124 [==============================] - 1s 7ms/step - loss: 12.1539\nEpoch 20/50\n124/124 [==============================] - 1s 7ms/step - loss: 11.9236\nEpoch 21/50\n124/124 [==============================] - 1s 7ms/step - loss: 11.7685\nEpoch 22/50\n124/124 [==============================] - 1s 7ms/step - loss: 11.6280\nEpoch 23/50\n124/124 [==============================] - 1s 7ms/step - loss: 11.3191\nEpoch 24/50\n124/124 [==============================] - 1s 7ms/step - loss: 11.2583\nEpoch 25/50\n124/124 [==============================] - 1s 7ms/step - loss: 11.2999\nEpoch 26/50\n124/124 [==============================] - 1s 7ms/step - loss: 11.1589\nEpoch 27/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.9604\nEpoch 28/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.8743\nEpoch 29/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.6604\nEpoch 30/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.6537\nEpoch 31/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.5623\nEpoch 32/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.4362\nEpoch 33/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.3773\nEpoch 34/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.2422\nEpoch 35/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.2777\nEpoch 36/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.3458\nEpoch 37/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.2443\nEpoch 38/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.1478\nEpoch 39/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.0789\nEpoch 40/50\n124/124 [==============================] - 1s 7ms/step - loss: 9.9985\nEpoch 41/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.1521\nEpoch 42/50\n124/124 [==============================] - 1s 7ms/step - loss: 10.0302\nEpoch 43/50\n124/124 [==============================] - 1s 7ms/step - loss: 9.9346\nEpoch 44/50\n124/124 [==============================] - 1s 7ms/step - loss: 9.9265\nEpoch 45/50\n124/124 [==============================] - 1s 7ms/step - loss: 9.8184\nEpoch 46/50\n124/124 [==============================] - 1s 7ms/step - loss: 9.8739\nEpoch 47/50\n124/124 [==============================] - 1s 8ms/step - loss: 9.8040\nEpoch 48/50\n124/124 [==============================] - 1s 7ms/step - loss: 9.7811\nEpoch 49/50\n124/124 [==============================] - 1s 7ms/step - loss: 9.5811\nEpoch 50/50\n124/124 [==============================] - 1s 7ms/step - loss: 9.5687\n16/16 [==============================] - 1s 4ms/step\n<function SMAPE at 0x79a69aec2c20>\nModel: \"sequential_13\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n masking_13 (Masking)        (None, 10, 227)           0         \n                                                                 \n conv1d_13 (Conv1D)          (None, 10, 16)            7280      \n                                                                 \n lstm_13 (LSTM)              (None, 64)                20736     \n                                                                 \n dense_13 (Dense)            (None, 4)                 260       \n                                                                 \n=================================================================\nTotal params: 28,276\nTrainable params: 28,276\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/50\n83/83 [==============================] - 3s 8ms/step - loss: 39.8260\nEpoch 2/50\n83/83 [==============================] - 1s 8ms/step - loss: 20.7290\nEpoch 3/50\n83/83 [==============================] - 1s 8ms/step - loss: 20.2057\nEpoch 4/50\n83/83 [==============================] - 1s 8ms/step - loss: 20.1549\nEpoch 5/50\n83/83 [==============================] - 1s 8ms/step - loss: 19.7427\nEpoch 6/50\n83/83 [==============================] - 1s 9ms/step - loss: 19.5510\nEpoch 7/50\n83/83 [==============================] - 1s 9ms/step - loss: 19.1561\nEpoch 8/50\n83/83 [==============================] - 1s 9ms/step - loss: 18.5407\nEpoch 9/50\n83/83 [==============================] - 1s 8ms/step - loss: 17.9727\nEpoch 10/50\n83/83 [==============================] - 1s 8ms/step - loss: 17.6642\nEpoch 11/50\n83/83 [==============================] - 1s 8ms/step - loss: 17.1550\nEpoch 12/50\n83/83 [==============================] - 1s 8ms/step - loss: 16.4546\nEpoch 13/50\n83/83 [==============================] - 1s 8ms/step - loss: 15.9618\nEpoch 14/50\n83/83 [==============================] - 1s 9ms/step - loss: 15.5067\nEpoch 15/50\n83/83 [==============================] - 1s 9ms/step - loss: 14.7806\nEpoch 16/50\n83/83 [==============================] - 1s 8ms/step - loss: 14.7827\nEpoch 17/50\n83/83 [==============================] - 1s 8ms/step - loss: 14.2779\nEpoch 18/50\n83/83 [==============================] - 1s 9ms/step - loss: 13.7953\nEpoch 19/50\n83/83 [==============================] - 1s 8ms/step - loss: 13.7339\nEpoch 20/50\n83/83 [==============================] - 1s 8ms/step - loss: 13.2900\nEpoch 21/50\n83/83 [==============================] - 1s 9ms/step - loss: 13.0659\nEpoch 22/50\n83/83 [==============================] - 1s 9ms/step - loss: 12.9738\nEpoch 23/50\n83/83 [==============================] - 1s 9ms/step - loss: 12.5775\nEpoch 24/50\n12/83 [===>..........................] - ETA: 0s - loss: 12.3662","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m Y:\n\u001b[1;32m      6\u001b[0m     sequential_split\u001b[38;5;241m.\u001b[39mappend(test_models(sequential_model, X, y))\n\u001b[0;32m----> 7\u001b[0m     sequential_kf3\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtest_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequential_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m     sequential_kf5\u001b[38;5;241m.\u001b[39mappend(test_models(sequential_model, X, y, kfold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m))\n","Cell \u001b[0;32mIn[3], line 259\u001b[0m, in \u001b[0;36mtest_models\u001b[0;34m(model_func, X_data, Y_data, eps, batch, kfold, test_size, concat)\u001b[0m\n\u001b[1;32m    257\u001b[0m         X_train, X_test \u001b[38;5;241m=\u001b[39m X_ftrain[train_index], X_ftrain[test_index]\n\u001b[1;32m    258\u001b[0m         Y_train, Y_test \u001b[38;5;241m=\u001b[39m Y_ftrain[train_index], Y_ftrain[test_index]\n\u001b[0;32m--> 259\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m         scores\u001b[38;5;241m.\u001b[39mappend(check_smape(model\u001b[38;5;241m.\u001b[39mpredict(X_test),Y_test))\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model_types = ['80/20 Split', 'K-Fold Cross Validation, 3 Folds', 'K-Fold Cross Validation, 5 Folds']\nfor i,models in enumerate([sequential_split, sequential_kf3, sequential_kf5]):\n    print(f'{model_types[i]}:')\n    for j,model_outputs in enumerate(models):\n        print()\n        print(f'UPDRS {j+1}:\\nTraining SMAPE Score: {model_outputs[1][-1]}\\nFirst 5 Predicted Values: \\n{np.round(model_outputs[2][0][:5])}\\nFirst 5 Actual Values: \\n{model_outputs[2][1][:5].reshape((5,4))}\\n')\n    print('\\n')\nplot_model(sequential_split[0], show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T05:37:22.594963Z","iopub.execute_input":"2023-05-08T05:37:22.595303Z","iopub.status.idle":"2023-05-08T05:37:22.632467Z","shell.execute_reply.started":"2023-05-08T05:37:22.595277Z","shell.execute_reply":"2023-05-08T05:37:22.631351Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"80/20 Split:\nUPDRS 1:\nTraining SMAPE Score: 4.624194743382185\nFirst 5 Predicted Values: \n[[4. 3. 3. 2.]\n [6. 7. 6. 7.]\n [6. 6. 6. 6.]\n [2. 2. 2. 2.]\n [6. 4. 4. 4.]]\nFirst 5 Actual Values: \n[[ 1. -1. -1. -1.]\n [-1. -1. -1. -1.]\n [-1.  5. -1. -1.]\n [ 3. -1.  2.  2.]\n [ 5. -1. -1. -1.]]\n\nUPDRS 2:\nTraining SMAPE Score: 6.90515665977837\nFirst 5 Predicted Values: \n[[-0.  0. -0.  0.]\n [11. 10. 11. 11.]\n [10.  9. 11. 11.]\n [-0.  0. -0.  0.]\n [-0.  0. -0.  0.]]\nFirst 5 Actual Values: \n[[-1. -1.  0.  0.]\n [11. -1. 13. 12.]\n [ 0. -1.  0. -1.]\n [ 0. -1.  0.  0.]\n [ 0. -1.  0. -1.]]\n\nUPDRS 3:\nTraining SMAPE Score: 2.0809923509641477\nFirst 5 Predicted Values: \n[[18. 19. 19. 22.]\n [23. 23. 24. 27.]\n [24. 24. 26. 28.]\n [18. 19. 19. 22.]\n [18. 19. 19. 22.]]\nFirst 5 Actual Values: \n[[-1. -1. -1. -1.]\n [26. 24. -1. 55.]\n [-1. -1. -1. -1.]\n [20. -1. 18. 18.]\n [ 7. -1. -1. -1.]]\n\nUPDRS 4:\nTraining SMAPE Score: 9.13693148512883\nFirst 5 Predicted Values: \n[[-0.  0. -0.  0.]\n [ 0.  0. -0.  0.]\n [ 0.  0. -0.  0.]\n [ 7.  6.  7.  7.]\n [-0.  0. -0. -0.]]\nFirst 5 Actual Values: \n[[-1. -1.  0.  0.]\n [-1. -1. -1. -1.]\n [-1. -1. -1. -1.]\n [-1. -1. -1. -1.]\n [-1. -1. -1. -1.]]\n\n\n\nK-Fold Cross Validation, 3 Folds:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_types[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j,model_outputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUPDRS \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining SMAPE Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_outputs[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFirst 5 Predicted Values: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(\u001b[43mmodel_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m5\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFirst 5 Actual Values: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_outputs[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m4\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plot_model(sequential_split[\u001b[38;5;241m0\u001b[39m], show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"],"ename":"IndexError","evalue":"tuple index out of range","output_type":"error"}]},{"cell_type":"code","source":"trained_model, scores = zip(*[train_models(sequential_model, X, y, kfold=3) for y in Y])    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(4):\n    print(f'model: {trained_model[i]}\\nscores: {scores[i]}\\n')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_submission_df(predictions, ids, loop):\n    updrs_list = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']\n    months = [0,6,12,18,24,36,48,60,72,84]\n    month = months[loop]\n    plus_list = [0,6,12,24]\n    \n    prediction_ids = []\n    \n    all_predictions = round_min_zero(predictions)\n    for i,preds in enumerate(all_predictions):\n        patient = 0\n        prediction_ids.append([])\n        preds = preds.reshape(4*len(preds))\n        for j,pred in enumerate(preds):\n            plus_month = plus_list[j%4]\n            prediction_ids[-1].append('_'.join([str(ids[patient]),str(month),updrs_list[i], 'plus', str(plus_month), 'months']))\n            patient += (j%4+1)//4\n    \n    dfs = []\n    for pred_ids, pred in zip(prediction_ids, all_predictions):\n        pred = pred.reshape(4*len(pred))\n        pred_ids = np.array(pred_ids)\n        dfs.append(pd.DataFrame({'prediction_id':pred_ids, 'rating':pred}).set_index('prediction_id'))\n\n    return pd.concat(dfs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import amp_pd_peptide_310\nenv = amp_pd_peptide_310.make_env()\niter_test = env.iter_test()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = None\nloop = 0\nfor (test, test_peptides, test_proteins, sample_submission) in iter_test:\n    if loop == 0:\n        data = pd.read_csv(test_proteins)\n    else:\n        data = pd.concat([data, pd.read_csv(test_proteins)], axis=0)\n    test_input, test_patients, correct_month = test_data_prep(data, train_uniprot_ids, scaler_object)\n    print(correct_month)\n    \n    # Double and Triple check that data is fully imputed aka no nan values\n    if test_input.isna().sum().sum() > 0:\n        test_input.fillna(data.mean(), inplace=True)\n        print('column mean imputation required')\n    if test_input.isna().sum().sum() > 0:\n        test_input.fillna(0, inplace=True)\n        print('zero imputation required')\n        print(test_input.head(10))\n    print(test_input.shape)\n    \n    temp_results = [model.predict(test_input) for model in trained_model]\n    \n    sample_submission = create_submission_df(temp_results, test_patients, loop)\n    \n    # final line, outputs csv for submission. Need to pass in a dataframe.\n    # columns are prediction_id and rating\n    env.predict(sample_submission)","metadata":{},"execution_count":null,"outputs":[]}]}